<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository><bug fixdate="2011-04-14 05:25:12" id="1959" opendate="2011-04-02 06:59:04"><buginformation><summary>[PIG-1959] Penny: a framework for workflow instrumentation - ASF JIRA</summary><description>Penny is a framework for instrumenting Pig workflows. It rewrites scripts to insert monitoring points, aka agents, and provides a communication framework for triggering and collecting events from these agents.</description></buginformation><fixedFiles><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ds.DSCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ri.RIMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GLMonitorAgent1.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ft.FTCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.Communicator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTInjectTaintMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.PennyServer.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.ParsedPigScript.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.MonitorAgentHarness.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.pig.MonitorAgentUDF.java</file><file>contrib.penny.java.src.test.java.org.apache.pig.penny.test.ComTest.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.lp.LPMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.nop.NOPMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.pig.PigLauncher.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.ClassWithArgs.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ds.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.SyncCallResult.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.CoordinatorHarness.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.Coordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ft.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.lp.LPCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.tr.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ti.TIMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.PhysicalLocation.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ci.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.NoSuchLocationException.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTMatchTaintMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ri.RICoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ci.CIMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.nop.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.dh.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.la.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ds.DSMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ti.TICoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.MonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.AsyncMessageReceiptCallback.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ci.CICoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.MessagingClient.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.MessageReceiptCallback.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ri.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.nop.NOPCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ft.FTMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.la.LACoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.lp.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.tr.TRCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.Message.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.goldenLogicClasses.FlattenLinksGL.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.pig.MonitorAgentUDFArgs.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.op.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.dh.DHCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ti.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.Location.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.op.OPMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GLMonitorAgent2.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTPropagateTaintMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.dh.DHMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GLCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GoldenLogic.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.MessagingServer.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.la.LAMonitorAgent.java</file><file>contrib.penny.java.src.test.java.org.apache.pig.penny.test.PennyAgentTest.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.LogicalLocation.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.op.OPCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.tr.TRMonitorAgent.java</file><file>src.org.apache.pig.tools.ToolsPigServer.java</file></fixedFiles></bug><bug fixdate="2011-03-22 09:27:22" id="1924" opendate="2011-03-20 11:01:57"><buginformation><summary>[PIG-1924] CSV Loader/Store that handles newlines in fields, and other Excel CSV features. - ASF JIRA</summary><description>CSVExcelStorage() combines load and store of CSV encoded data. Handles newlines within fields, escaped double quotes, and double quoting of fields with embedded field delimiters. Newline handling is optional, and controlled by a parameter. The module also offers an option to output with Windows style newlines (CRLF, instead of the Unix LF). All CSV related syntax decisions were made to match Excel 2007. The module comes with a test file, and javadoc produces proper documentation files.</description></buginformation><fixedFiles><file>contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.storage.TestCSVExcelStorage.java</file></fixedFiles></bug><bug fixdate="2011-04-13 01:10:20" id="1881" opendate="2011-03-03 05:34:33"><buginformation><summary>[PIG-1881] Need a special interface for Penny (Inspector Gadget) - ASF JIRA</summary><description>The proposed Penny tool needs access to Pig's new logical plan in order to inject code into the the dataflow. Once it has modified the plan it needs to then be able to hand back that modified plan and have Pig execute it. As we don't want to open this functionality up to general users, the proposal is to do this by subclasses PigServer with a new class that is marked as LimitedPrivate for Penny only. This class will provide calls to parse a Pig Latin script and return a logical plan, and one to take a logical plan and execute it.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.tools.grunt.GruntParser.java</file><file>test.org.apache.pig.test.TestToolsPigServer.java</file><file>src.org.apache.pig.tools.ToolsPigServer.java</file></fixedFiles></bug><bug fixdate="2011-03-09 10:52:10" id="1876" opendate="2011-03-01 11:54:23"><buginformation><summary>[PIG-1876] Typed map for Pig - ASF JIRA</summary><description>Currently Pig map type is untyped, which means map value is always of bytearray(ie. unknown) type. In PIG-1277, we allow unknown type to be a shuffle key, which somewhat relieve the problem. However, typed map is still beneficial in that: 1. User can make semantic use of the map value type. Currently, user need to explicitly cast map value, which is ugly 2. Though PIG-1277 allow unknown type be a shuffle key, the performance suffers. We don't have a raw comparator for the unknown type, instead, we need to instantiate the value object and invoke its comparator Here is proposed syntax for typed map: map[type] Typed map can be used in place of untyped map could occur. For example: a = load '1.txt' as(map[int]); b = foreach a generate (map[(i:int)])a0; - - Map value is tuple b = stream a through `cat` as (m:map[ {(i:int,j:chararray)} ]); - - Map value is bag MapLookup a typed map will result datatype of map value. a = load '1.txt' as(map[int]); b = foreach a generate $0#'key'; Schema for b: b: {int} The behavior of untyped map will remain the same.</description></buginformation><fixedFiles><file>src.org.apache.pig.LoadCaster.java</file><file>src.org.apache.pig.builtin.TextLoader.java</file><file>src.org.apache.pig.builtin.BinStorage.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file><file>src.org.apache.pig.data.DataType.java</file><file>src.org.apache.pig.builtin.Utf8StorageConverter.java</file><file>test.org.apache.pig.test.TestPOCast.java</file><file>src.org.apache.pig.impl.io.ReadToEndLoader.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalSchema.java</file><file>src.org.apache.pig.newplan.logical.visitor.ColumnAliasConversionVisitor.java</file><file>src.org.apache.pig.impl.logicalLayer.schema.Schema.java</file><file>src.org.apache.pig.newplan.logical.expression.MapLookupExpression.java</file><file>src.org.apache.pig.ResourceSchema.java</file><file>src.org.apache.pig.backend.hadoop.hbase.HBaseBinaryConverter.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.java</file><file>src.org.apache.pig.newplan.logical.LogicalExpPlanMigrationVistor.java</file><file>test.org.apache.pig.test.TestTypedMap.java</file></fixedFiles></bug><bug fixdate="2011-02-23 11:02:28" id="1794" opendate="2011-01-09 10:51:53"><buginformation><summary>[PIG-1794] Javascript support for Pig embedding and UDFs in scripting languages - ASF JIRA</summary><description>The attached patch proposes a javascript implementation for Pig embedding and UDFs in scripting languages. It is similar to the Jython implementation and uses Rhino provided in the JDK. some differences: output schema is provided by: &lt;functionName&gt;.outSchema="&lt;schema&gt;" as javascript does not have annotations or decorators but functions are first class objects tuples are converted to objects using the input schema (the other way around using the output schema) The attached patch is not final yet. In particular it lacks unit tests. See test/org/apache/pig/test/data/tc.js for the "transitive closure" example See the following JIRAs for more context: https://issues.apache.org/jira/browse/PIG-928 https://issues.apache.org/jira/browse/PIG-1479</description></buginformation><fixedFiles><file>src.org.apache.pig.scripting.Pig.java</file><file>src.org.apache.pig.scripting.ScriptPigContext.java</file><file>src.org.apache.pig.Main.java</file><file>test.org.apache.pig.test.TestScriptLanguageJavaScript.java</file><file>src.org.apache.pig.scripting.js.JSPig.java</file><file>test.org.apache.pig.test.Util.java</file><file>src.org.apache.pig.scripting.ScriptEngine.java</file><file>src.org.apache.pig.scripting.js.Pig.java</file><file>src.org.apache.pig.scripting.js.JsFunction.java</file><file>src.org.apache.pig.scripting.js.JsScriptEngine.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file></fixedFiles></bug><bug fixdate="2011-02-15 01:09:47" id="1793" opendate="2011-01-08 12:10:15"><buginformation><summary>[PIG-1793] Add macro expansion to Pig Latin - ASF JIRA</summary><description>As production Pig scripts grow longer and longer, Pig Latin has a need to integrate standard programming techniques of separation and code sharing offered by functions and modules. A proposal of adding macro expansion to Pig Latin is posted here: http://wiki.apache.org/pig/TuringCompletePig Below is a brief summary of the proposed syntax (and examples): Macro Definition The existing DEFINE keyword will be expanded to allow definitions of Pig macros. Syntax &#13;
define &lt;name&gt; (&lt;params&gt;) returns &lt;aliases&gt; {&#13;
    &lt;Pig Latin fragment&gt;&#13;
};&#13;
 Example &#13;
define my_macro(A, sortkey) returns C {&#13;
    B = filter $A by my_filter(*);&#13;
    $C = order B by $sortkey;&#13;
}&#13;
 Macro Expansion Syntax &#13;
&lt;aliases&gt; = &lt;macro name&gt; (&lt;params&gt;);&#13;
 Example: Use above macro in a Pig script: &#13;
X = load 'foo' as (user, address, phone);&#13;
Y = my_macro(X, user);&#13;
store Y into 'bar';&#13;
 This script is expanded into the following Pig Latin statements: &#13;
X = load 'foo' as (user, address, phone);&#13;
macro_my_macro_B_1 = filter X by my_filter(*);&#13;
Y = order macro_my_macro_B_1 by user;&#13;
store Y into 'bar';&#13;
 Notes 1. Any alias in the macro which isn't visible from outside will be prefixed with macro name and suffixed with instance id to avoid namespace collision. 2. Macro expansion is not a complete replacement for function calls. Recursive expansions are not supported. Macro Import The new IMPORT keyword can be used to add macros defined in another Pig Latin file. Syntax &#13;
import &lt;Pig Latin file name&gt;;&#13;
 Example &#13;
import my_macro.pig;&#13;
 Note: All macro names are in the global namespace.</description></buginformation><fixedFiles><file>src.org.apache.pig.scripting.Pig.java</file><file>src.org.apache.pig.parser.ParserUtil.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.parser.PigMacro.java</file></fixedFiles></bug><bug fixdate="2011-04-17 08:01:05" id="1782" opendate="2010-12-30 04:32:26"><buginformation><summary>[PIG-1782] Add ability to load data by column family in HBaseStorage - ASF JIRA</summary><description>It would be nice to load all columns in the column family by using short hand syntax like: CpuMetrics = load 'hbase://SystemMetrics' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cpu:','-loadKey');&#13;
 Assuming there are columns cpu: sys.0, cpu:sys.1, cpu:user.0, cpu:user.1, in cpu column family. CpuMetrics would contain something like: (rowKey, cpu:sys.0, cpu:sys.1, cpu:user.0, cpu:user.1)</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.hbase.HBaseStorage.java</file><file>src.org.apache.pig.backend.hadoop.hbase.HBaseTableInputFormat.java</file><file>a.src.org.apache.pig.backend.hadoop.hbase.HBaseStorage.java</file><file>a.test.org.apache.pig.test.TestHBaseStorage.java</file><file>test.org.apache.pig.test.TestHBaseStorage.java</file></fixedFiles></bug><bug fixdate="2010-12-10 01:40:24" id="1758" opendate="2010-12-07 11:43:13"><buginformation><summary>[PIG-1758] Deep cast of complex type - ASF JIRA</summary><description>Pig does not handle deep cast from bag -&gt; bag, tuple -&gt; tuple. Eg, the following script does not produce desired result: &#13;
a = load '1.txt' as (a0:bag{t:tuple(i0:double)});&#13;
b = foreach a generate (bag{tuple(int)})a0;&#13;
dump b;&#13;
 The result tuple still contain int inside tuple of bag. PIG-613 fix the case we cast bytearray &gt; bag/tuple, we take complex type including inner types, but bag&gt;bag, tuple-&gt;tuple is still not effective.</description></buginformation><fixedFiles><file>test.org.apache.pig.test.TestPOCast.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.java</file></fixedFiles></bug><bug fixdate="2010-12-06 09:45:10" id="1752" opendate="2010-12-03 12:49:40"><buginformation><summary>[PIG-1752] UDFs should be able to indicate files to load in the distributed cache - ASF JIRA</summary><description>Currently there is no way for a UDF to load a file into the distributed cache.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.java</file><file>src.org.apache.pig.EvalFunc.java</file><file>src.org.apache.pig.newplan.logical.expression.ExpToPhyTranslationVisitor.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.java</file></fixedFiles></bug><bug fixdate="2010-11-16 06:24:52" id="1722" opendate="2010-11-12 04:29:48"><buginformation><summary>[PIG-1722] PiggyBank AllLoader - Load multiple file formats in one load statement - ASF JIRA</summary><description>This gives the ability to point one loader at a directory and have multiple formats loaded and used in the same query ----- Overview ----- Lets say we have a directory with files: /logs/myfile.lzo /logs/myfile.rc /logs/myfile.bz2 /logs/myfile.gz To load these currently requires multiple loaders, load statements in pig and then have the query perform a union on these. With this Loader the query becomes: a = LOAD '/logs/' USING org.apache.pig.piggybank.storage.AllLoader(); The AllLoader will use the mapping property in the $PIG_HOME/conf/pig.properties file.extension.loaders that can be setup as: file.extension.loaders=gz:org.apache.pig.builtin.PigStorage(),bz2:org.apache.pig.builtin.PigStorage(),lzo:com.twitter.elephantbird.pig.load.LzoTextLoader(), rc:org.apache.pig.piggybank.storage.HiveColumnarLoader() The formats of this property is: -&gt; [file extension]:[loader func spec] -&gt; [file-extension]:[optional path tag]:[loader func spec] -&gt; [file-extension]:[optional path tag]:[sequence file key value writer class name]:[loader func spec] ----- File path tagging: ----- Loaders can also be chosen based on folder names in the file path: e.g. file.extension.loaders:gz:type1:Type1Loader(), gz:type2:Type2Loader() So that if you have /logs/type1/mylog and /logs/type2/mylog doing : a = LOAD '/logs/' USING org.apache.pig.piggybank.storage.AllLoader(); will use Type1Loader for mylog in /logs/type1 and Type2Loader for mylog in /logs/type2 ----- File content guessing: ----- If the files do not have extensions the AllLoader will try to guess the type of file by looking at the first three bytes mapping the following bytes to each extension: [ -119, 76, 90 ] = lzo [ 31, -117, 8 ] = gz [ 66, 90, 104 ] = bz2 [ 83, 69, 81 ] = seq ----- Loader selection based on sequence file writer class ----- Loaders can be configured to be selected based on the getKeyClassName of the Sequence File. e.g. file.extension.loaders:seq::org.apache.hadoop.hive.ql.io.RCFile:HiveColumnarLoader will use the HiveColumnarLoader loader for all sequence files that have been written with org.apache.hadoop.hive.ql.io.RCFile as the KeyClassName. All $ extensions are removed from the getKeyClassName's return value. ----- Path Partition Handling ----- Hive style partitioning is supported in the Loader itself so that if you have /logs/type=1 /logs/type=2 /logs/type=3 The partition columns will be recougnised as "type" and filtering can be done like type&lt;=2 etc. For this current implementation filtering expressions should be passed into the AllLoader's constructor e.g. a = LOAD '/logs/' USING org.apache.pig.piggybank.storage.AllLoader('type&lt;=2'); will load only files that are in /logs/type=1 and /logs/type=2</description></buginformation><fixedFiles><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.AllLoader.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.allloader.LoadFuncHelper.java</file><file>contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.storage.TestAllLoader.java</file><file>contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.storage.TestLoadFuncHelper.java</file></fixedFiles></bug><bug fixdate="2011-03-28 02:02:17" id="1693" opendate="2010-10-22 06:55:22"><buginformation><summary>[PIG-1693] support project-range expression. (was: There needs to be a way in foreach to indicate "and all the rest of the fields" ) - ASF JIRA</summary><description>A common use case we see in Pig is people have many columns in their data and they only want to operate on a few of them. Consider for example if before storing data with ten columns, the user wants to perform a cast on one column: &#13;
...&#13;
Z = foreach Y generate (int)firstcol, secondcol, thridcol, forthcol, fifthcol, sixthcol, seventhcol, eigthcol, ninethcol, tenthcol;&#13;
store Z into 'output';&#13;
 Obviously this only gets worse as the user has more columns. Ideally the above could be transformed to something like: &#13;
...&#13;
Z = foreach Y generate (int)firstcol, "and all the rest";&#13;
store Z into 'output'</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.relational.LOSort.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange.java</file><file>src.org.apache.pig.newplan.logical.rules.MergeForEach.java</file><file>src.org.apache.pig.newplan.logical.expression.ExpToPhyTranslationVisitor.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.CombinerOptimizer.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.ColumnInfo.java</file><file>src.org.apache.pig.newplan.logical.expression.ProjectExpression.java</file><file>src.org.apache.pig.newplan.logical.relational.LOInnerLoad.java</file><file>src.org.apache.pig.newplan.logical.visitor.ColumnAliasConversionVisitor.java</file><file>src.org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.java</file><file>test.org.apache.pig.test.TestProjectRange.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizer.java</file><file>src.org.apache.pig.newplan.logical.rules.ColumnPruneHelper.java</file><file>src.org.apache.pig.PigWarning.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PORelationToExprProject.java</file><file>test.org.apache.pig.test.Util.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort.java</file><file>src.org.apache.pig.newplan.logical.visitor.ProjectStarExpander.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.java</file><file>src.org.apache.pig.newplan.logical.rules.FilterAboveForeach.java</file><file>src.org.apache.pig.parser.LogicalPlanBuilder.java</file><file>src.org.apache.pig.parser.ParserException.java</file></fixedFiles></bug><bug fixdate="2011-01-07 10:18:01" id="1479" opendate="2010-07-01 09:30:01"><buginformation><summary>[PIG-1479] Embed Pig in scripting languages - ASF JIRA</summary><description>It should be possible to embed Pig calls in a scripting language and let functions defined in the same script available as UDFs. This is a spin off of https://issues.apache.org/jira/browse/PIG-928 which lets users define UDFs in scripting languages.</description></buginformation><fixedFiles><file>src.org.apache.pig.scripting.BoundScript.java</file><file>src.org.apache.pig.tools.pigstats.EmbeddedPigStats.java</file><file>src.org.apache.pig.scripting.Pig.java</file><file>src.org.apache.pig.tools.pigstats.OutputStats.java</file><file>test.org.apache.pig.test.TestPigRunner.java</file><file>src.org.apache.pig.scripting.ScriptPigContext.java</file><file>src.org.apache.pig.tools.pigstats.PigStatsUtil.java</file><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.tools.pigstats.PigProgressNotificationListener.java</file><file>src.org.apache.pig.scripting.SyncProgressNotificationAdaptor.java</file><file>src.org.apache.pig.scripting.ScriptPigServer.java</file><file>src.org.apache.pig.scripting.jython.JythonFunction.java</file><file>test.org.apache.pig.test.TestScriptLanguage.java</file><file>src.org.apache.pig.tools.pigstats.PigStats.java</file><file>src.org.apache.pig.scripting.ScriptEngine.java</file><file>src.org.apache.pig.tools.pigstats.SimplePigStats.java</file><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.tools.pigstats.ScriptState.java</file><file>src.org.apache.pig.scripting.jython.JythonUtils.java</file><file>src.org.apache.pig.scripting.MultiBoundPipeline.java</file><file>src.org.apache.pig.scripting.BoundPipeline.java</file><file>src.org.apache.pig.scripting.PigPipeline.java</file><file>src.org.apache.pig.tools.pigstats.JobStats.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file></fixedFiles></bug></bugrepository>