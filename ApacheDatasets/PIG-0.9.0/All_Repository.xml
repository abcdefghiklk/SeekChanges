<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository><bug fixdate="2011-07-19 12:48:18" id="2159" opendate="2011-07-13 12:41:01"><buginformation><summary>[PIG-2159] New logical plan uses incorrect class for SUM causing for ClassCastException - ASF JIRA</summary><description>The below is my script; &#13;
A = load 'input1' using PigStorage(',')  as (f1:int,f2:int,f3:int,f4:long,f5:double);&#13;
B = load 'input2' using PigStorage(',')  as (f1:int,f2:int,f3:int,f4:long,f5:double);&#13;
C = load 'input_Main' using PigStorage(',')  as (f1:int,f2:int,f3:int);&#13;
U = UNION ONSCHEMA A,B;&#13;
J = join C by (f1,f2,f3) LEFT OUTER, U by (f1,f2,f3);&#13;
Porj = foreach J generate C::f1 as f1 ,C::f2 as f2,C::f3 as f3,U::f4 as f4,U::f5 as f5;&#13;
G = GROUP Porj by (f1,f2,f3,f5);&#13;
Final = foreach G generate SUM(Porj.f4) as total;&#13;
dump Final;&#13;
 The script fails at while computing the sum with class cast exception. Caused by: java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.Double at org.apache.pig.builtin.DoubleSum$Initial.exec(DoubleSum.java:82) ... 19 more This is clearly a bug in the logical plan created in 0.9. The sum operation should have processed using org.apache.pig.builtin.LongSum, but instead 0.9 logical plan have used org.apache.pig.builtin.DoubleSum which is meant for sum of doubles. And hence the ClassCastException. The same script works fine with Pig 0.8.</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.relational.LOUnion.java</file><file>test.org.apache.pig.parser.TestUnionOnSchemaSetter.java</file><file>test.org.apache.pig.test.TestEvalPipeline2.java</file></fixedFiles></bug><bug fixdate="2011-07-20 11:58:19" id="2146" opendate="2011-06-28 12:56:32"><buginformation><summary>[PIG-2146] POStore.getSchema() returns null because of which PigOutputCommitter is not storing schema while cleanup - ASF JIRA</summary><description>The below is my script; &#13;
register piggybank.jar;&#13;
a = load 'myinput' using PigStorage(',') as (f1:chararray,f2:chararray,f3:chararray);&#13;
b = distinct a;&#13;
c = limit b 2;&#13;
store c into 'pss001' using org.apache.pig.piggybank.storage.PigStorageSchema();&#13;
 Input ------- a,1,aa b,2,bb c,3,cc For this script , PigStorageSchema is not generating .pig_headers and .pig_schema files. While debugging I could see that storeSchema(..) method itself is not invoked.The schema object for the store is returned as null (POStore.getSchema()) because of which PigOutputCommitter is not invoking the storSchema. The same schema object is valid when I run it in local mode. This issue is happening for Pig 0.9 also.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.java</file><file>test.org.apache.pig.test.TestLimitSchemaStore.java</file><file>test.org.apache.pig.test.TestMRCompiler.java</file></fixedFiles></bug><bug fixdate="2011-06-29 01:32:02" id="2144" opendate="2011-06-27 03:23:46"><buginformation><summary>[PIG-2144] ClassCastException when using IsEmpty(DIFF()) - ASF JIRA</summary><description>I have following input &lt;name&gt;:&lt;nickname&gt;, for which I want to find records where name is different from nickname. input/name_nickname.txt &#13;
Bharat:Bharat&#13;
Amita:Amita&#13;
Mitesh:Mitesh&#13;
Reenu:Anshu&#13;
Shikha:Shikhu&#13;
Shilpa:Shilpi&#13;
 I have following script to find records where name is different from nickname. isEmpty_diff.pig &#13;
&#13;
A = LOAD 'input/name_nickname.txt' using PigStorage(':');&#13;
&#13;
B = FILTER A BY NOT IsEmpty(DIFF($0, $1));&#13;
&#13;
DUMP B;&#13;
 The above pig script works with older pig versions (e.g. 0.8.0 (r1043805)) and gives following output output of isEmpty_diff.pig &#13;
(Reenu,Anshu)&#13;
(Shikha,Shikhu)&#13;
(Shilpa,Shilpi)&#13;
 However, the above pig script (isEmpty_diff.pig) fails on Pig 0.9 (e.g. 0.9.0.xx (r1127671)) and newer version of Pig 0.8 (e.g. version 0.8.0.xx (r1102885)) , with ClassCastException ClassCastException &#13;
java.lang.ClassCastException: org.apache.pig.data.DefaultDataBag cannot be cast to java.lang.Boolean&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PONot.getNext(PONot.java:75)&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator.getNext(PhysicalOperator.java:318)&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.processInput(POUserFunc.java:159)&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.getNext(POUserFunc.java:184)&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.getNext(POUserFunc.java:269)&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PONot.getNext(PONot.java:71)&#13;
        at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POFilter.getNext(POFilter.java:148)&#13;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:261)&#13;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:256)&#13;
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:58)&#13;
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)&#13;
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:676)&#13;
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:336)&#13;
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:210)&#13;
 As a workaround, I used the following pig script. &#13;
A = LOAD 'input/name_nickname.txt' using PigStorage(':');&#13;
&#13;
--B = FILTER A BY NOT IsEmpty(DIFF($0, $1));&#13;
B1 = FOREACH A GENERATE $0, $1, DIFF($0, $1);&#13;
B2 = FILTER B1 BY NOT IsEmpty($2);&#13;
B = FOREACH B2 GENERATE $0, $1;&#13;
&#13;
DUMP B;</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.newplan.logical.rules.NotConversionVisitor.java</file><file>test.org.apache.pig.test.TestFilterSimplification.java</file></fixedFiles></bug><bug fixdate="2011-06-23 12:35:21" id="2140" opendate="2011-06-22 09:06:41"><buginformation><summary>[PIG-2140] Usage printed from Main.java gives wrong option for disabling LogicalExpressionSimplifier - ASF JIRA</summary><description>The correct command line option for disabling LogicalExpressionSimplifier is "-t FilterLogicExpressionSimplifier" , not "-t LogicalExpressionSimplifier".</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file></fixedFiles></bug><bug fixdate="2011-06-25 01:07:14" id="2139" opendate="2011-06-22 08:58:52"><buginformation><summary>[PIG-2139] LogicalExpressionSimplifier optimizer rule should check if udf is deterministic while checking if they are equal - ASF JIRA</summary><description>LogicalExpressionSimplifier simplifies filter expressions. In the process, it compares udfs to see if they are 'equal' (ie expected to produce same results). But it does not check if the udfs are annotated as @Nondeterministic. If such an annotation exists, then the udfs should not be considered equal. UserFuncition.isEqual() is being used to compare the udfs.</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.expression.UserFuncExpression.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalPlan.java</file><file>src.org.apache.pig.newplan.logical.rules.OptimizerUtils.java</file><file>test.org.apache.pig.test.TestFilterSimplification.java</file></fixedFiles></bug><bug fixdate="2011-06-24 03:39:20" id="2137" opendate="2011-06-22 04:33:41"><buginformation><summary>[PIG-2137] SAMPLE should not be pushed above DISTINCT - ASF JIRA</summary><description>I have an input file that contains 50,000 distinct integers. Each integer is repeated twice, for a total of 100,000 lines. Script 1, using GROUP BY to get distinct entries in the data, works: &#13;
&#13;
grunt&gt; f = load 'tmp/dupnumbers.txt';              &#13;
grunt&gt; d = foreach (group f by $0) generate group; &#13;
grunt&gt; s = sample d 0.01;                          &#13;
grunt&gt; n = foreach (group s all) generate COUNT(s);&#13;
grunt&gt; dump n;&#13;
(493)&#13;
 Script 2, using DISTINCT for the same purpose, allows sampling to be done before DISTINCT: &#13;
grunt&gt; f = load 'tmp/dupnumbers.txt';              &#13;
grunt&gt; d = distinct f;&#13;
grunt&gt; s = sample d 0.01;                          &#13;
grunt&gt; n = foreach (group s all) generate COUNT(s);&#13;
(980)</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.rules.PushUpFilter.java</file><file>test.org.apache.pig.test.TestNewPlanFilterRule.java</file></fixedFiles></bug><bug fixdate="2011-06-01 11:10:02" id="2106" opendate="2011-06-01 10:56:37"><buginformation><summary>[PIG-2106] Fix Zebra unit test TestBasicUnion.testNeg3, TestBasicUnion.testNeg4 - ASF JIRA</summary><description>Two zebra unit tests are broken after PIG-2084. We need to fix them.</description></buginformation><fixedFiles><file>contrib.zebra.src.test.org.apache.hadoop.zebra.pig.TestBasicUnion.java</file></fixedFiles></bug><bug fixdate="2011-05-24 01:12:18" id="2089" opendate="2011-05-23 09:06:07"><buginformation><summary>[PIG-2089] Javadoc for ResourceFieldSchema.getSchema() is wrong - ASF JIRA</summary><description>Javadoc says: "Only fields of type tuple should have a schema". Actually bag, map(starting from 0.9) also can have schema.</description></buginformation><fixedFiles><file>src.org.apache.pig.ResourceSchema.java</file></fixedFiles></bug><bug fixdate="2011-05-23 09:19:33" id="2088" opendate="2011-05-23 07:32:50"><buginformation><summary>[PIG-2088] Return alias validation failed when there is single line comment in the macro - ASF JIRA</summary><description>The following script &#13;
define test() returns b { &#13;
   a = load 'data' as (name, age, gpa);&#13;
-- message &#13;
   $b = filter a by (int)age &gt; 40; &#13;
};&#13;
&#13;
beta = test();&#13;
store beta into 'output';&#13;
 results in a validation failure: &#13;
ERROR 1200 "Macro test missing return alias b"</description></buginformation><fixedFiles><file>src.org.apache.pig.parser.PigMacro.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-05-23 09:37:31" id="2084" opendate="2011-05-20 06:44:01"><buginformation><summary>[PIG-2084] pig is running validation for a statement at a time batch mode, instead of running it for whole script - ASF JIRA</summary><description>In PIG-2059, a change was made to run validation for each statement instead of running it once for the whole script. This slows down the validation phase, and it ends up taking tens of seconds.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.tools.grunt.Grunt.java</file><file>src.org.apache.pig.tools.grunt.GruntParser.java</file><file>test.org.apache.pig.parser.TestErrorHandling.java</file><file>test.org.apache.pig.test.TestBuiltin.java</file><file>test.org.apache.pig.test.TestDataBagAccess.java</file><file>test.org.apache.pig.test.TestGrunt.java</file><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file><file>test.org.apache.pig.test.TestNewPlanLogToPhyTranslationVisitor.java</file><file>test.org.apache.pig.test.TestPigServer.java</file></fixedFiles></bug><bug fixdate="2011-05-25 08:53:02" id="2083" opendate="2011-05-20 06:22:45"><buginformation><summary>[PIG-2083] bincond ERROR 1025: Invalid field projection when null is used - ASF JIRA</summary><description>This is a regression for 9. a = load '1.txt' as (a0, a1); b = foreach a generate (a0==0?null:2); explain b; ERROR 1025: Invalid field projection. Projected field [null] does not exist in schema</description></buginformation><fixedFiles><file>test.org.apache.pig.parser.TestQueryParser.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-05-20 08:24:34" id="2081" opendate="2011-05-19 07:58:19"><buginformation><summary>[PIG-2081] Dryrun gives wrong line numbers in error message for scripts containing macro. - ASF JIRA</summary><description>For following script (test.pig) &#13;
1 DEFINE my_macro (X,key) returns Y&#13;
  2         {&#13;
  3         tmp1 = foreach  $X generate TOKENIZE((chararray)$key) as tokens;&#13;
  4         tmp2 = foreach tmp1 generate flatten(tokens);&#13;
  5         tmp3 = order tmp2 by $0;&#13;
  6         $Y = distinct tmp3;&#13;
  7         }&#13;
  8 &#13;
  9 A = load 'sometext' using TextLoader() as (row) ;&#13;
 10 E = my_macro(A,row);&#13;
 11 &#13;
 12 A1 = load 'sometext2' using TextLoader() as (row1);&#13;
 13 E1 = my_macro(A1,row1);&#13;
 14 &#13;
 15 A3 = load 'sometext3' using TextLoader() as (row3);&#13;
 16 E3 = my_macro(A3,$0);&#13;
 17 &#13;
 18 F = cogroup E by $0, E1 by $0,E3 by $0;&#13;
 19 dump F;&#13;
 pig test.pig gives correct line number in error message: &#13;
ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: &lt;file test.pig, line 16, column 17&gt;  mismatched input '$0' expecting set null&#13;
 while pig -r test.pig gives incorrect line number in error message: &#13;
ERROR org.apache.pig.Main - ERROR 1200: &lt;file test.pig.substituted, line 1, column 17&gt;  mismatched input '$0' expecting set null</description></buginformation><fixedFiles><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-05-19 10:28:27" id="2078" opendate="2011-05-18 06:29:40"><buginformation><summary>[PIG-2078] POProject.getNext(DataBag) does not handle null - ASF JIRA</summary><description>The following script fail with "-t MergeForEach" &#13;
a = load '1.txt' as (a0:bag{}, a1:int);&#13;
b = foreach a generate a0;&#13;
dump b;&#13;
 1.txt: {(1)} 2 3 Error stack: java.lang.NullPointerException at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.consumeInputBag(POProject.java:310) at org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.getNext(POProject.java:251) at org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator.getNext(PhysicalOperator.java:316) at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.processPlan(POForEach.java:332) at org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.getNext(POForEach.java:284) at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.runPipeline(PigMapBase.java:261) at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:256) at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigMapBase.map(PigMapBase.java:1) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:621) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305) at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:177)</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.java</file><file>test.org.apache.pig.test.TestEvalPipeline2.java</file></fixedFiles></bug><bug fixdate="2011-05-16 05:13:55" id="2076" opendate="2011-05-14 12:53:17"><buginformation><summary>[PIG-2076] update documentation, help command with correct default value of pig.cachedbag.memusage - ASF JIRA</summary><description>The default value of pig.cachedbag.memusage was changed to 0.2 in pig 0.8, as part of changes in PIG-1447 . But the help command and documentation shows older default value of 0.1 .</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file></fixedFiles></bug><bug fixdate="2011-05-16 04:59:39" id="2072" opendate="2011-05-13 08:05:02"><buginformation><summary>[PIG-2072] NPE when udf has project-star argument and input schema is null - ASF JIRA</summary><description>grunt&gt; l = load 'x' ;                 &#13;
grunt&gt; f = foreach l generate CONCAT(*);&#13;
2011-05-13 12:04:48,355 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2999: Unexpected internal error. null</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.visitor.TypeCheckingExpVisitor.java</file><file>test.org.apache.pig.test.TestProjectStarRangeInUdf.java</file></fixedFiles></bug><bug fixdate="2011-05-16 07:44:53" id="2071" opendate="2011-05-13 07:06:18"><buginformation><summary>[PIG-2071] casting numeric type to chararray during schema merge for union is inconsistent with other schema merge cases - ASF JIRA</summary><description>In PIG-1536, if a column in output of union has a source column one input of type charraray and in other it is of a numeric type, the column of numeric type will be cast to chararray. But in all other cases, chararray and numeric types are considered incompatible, and as a result such implicit casting is not done. To be consistent with other cases, union also should consider chararray and numeric types to be incompatible.</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.relational.LogicalSchema.java</file><file>test.org.apache.pig.parser.TestUnionOnSchemaSetter.java</file><file>test.org.apache.pig.test.TestSchema.java</file><file>test.org.apache.pig.test.TestUnionOnSchema.java</file></fixedFiles></bug><bug fixdate="2011-05-16 07:57:11" id="2070" opendate="2011-05-13 07:04:48"><buginformation><summary>[PIG-2070] "Unknown" appears in error message for an error case - ASF JIRA</summary><description>For the following query: a = load '1.txt' as (a0:int, a1:int); b = load '2.txt' as (a0:int, a1:chararray); c = cogroup a by (a0,a1), b by (a0,a1); Pig gives the following message, which includes "unknown" word. 2011-05-13 11:01:18,682 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1051: &lt;line 3, column 4&gt; Cannot cast to Unknown The error message should be more meaningful.</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.visitor.TypeCheckingRelVisitor.java</file><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file></fixedFiles></bug><bug fixdate="2011-05-16 06:15:08" id="2069" opendate="2011-05-13 03:19:30"><buginformation><summary>[PIG-2069] LoadFunc jar does not ship to backend in MultiQuery case - ASF JIRA</summary><description>Pig is able to automatically figure out the jar containing the LoadFunc and ship them to backend. However, the following script didn't: &#13;
A = load '1.txt' using SomeLoadFunc();&#13;
B = filter A by $0==0;&#13;
C = filter A by $1==1;&#13;
D = join B by $0, C by $0;&#13;
dump D;&#13;
 The reason is this query is a multiquery (A is reused and thus create an implicit split). When we merge multiquery into one job, we didn't merge udfs list properly.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer.java</file></fixedFiles></bug><bug fixdate="2011-05-13 09:38:43" id="2067" opendate="2011-05-12 11:31:21"><buginformation><summary>[PIG-2067] FilterLogicExpressionSimplifier removed some branches in some cases - ASF JIRA</summary><description>The following script produce wrong result: &#13;
A = load 'a.dat' as (cookie);&#13;
B = load 'b.dat' as (cookie);&#13;
C = cogroup A by cookie, B by cookie;&#13;
E = filter C by COUNT(B)&gt;0 AND COUNT(A)&gt;0;&#13;
explain E;&#13;
 a.dat: 1 1 2 2 3 3 4 4 5 5 6 6 7 7 b.dat: 3 3 4 4 5 5 6 6 7 7 8 8 Expected output: (3, {(3)},{(3)} ) (4, {(4)},{(4)} ) (5, {(5)},{(5)} ) (6, {(6)},{(6)} ) (7, {(7)},{(7)} ) We get: (3, {(3)},{(3)} ) (4, {(4)},{(4)} ) (5, {(5)},{(5)} ) (6, {(6)},{(6)} ) (7, {(7)},{(7)} ) (8,{}, {(8)} )</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.expression.UserFuncExpression.java</file><file>test.org.apache.pig.test.TestFilterSimplification.java</file></fixedFiles></bug><bug fixdate="2011-05-13 07:13:31" id="2062" opendate="2011-05-12 06:38:54"><buginformation><summary>[PIG-2062] Script silently ended - ASF JIRA</summary><description>The following script ended silently without execution. &#13;
a = load '1.txt' as (a0, a1);&#13;
b = load '2.txt' as (b0, b1);&#13;
all = join a by a0, b by b0;&#13;
store all into '1111';&#13;
 If change the alias "all", it will run. We need to throw exception saying "all" is a keyword.</description></buginformation><fixedFiles><file>test.org.apache.pig.parser.TestLogicalPlanGenerator.java</file><file>test.org.apache.pig.test.TestCombiner.java</file><file>test.org.apache.pig.test.TestExampleGenerator.java</file><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file></fixedFiles></bug><bug fixdate="2011-05-13 07:58:48" id="2059" opendate="2011-05-11 01:06:19"><buginformation><summary>[PIG-2059] PIG doesn't validate incomplete query in batch mode even if -c option is given - ASF JIRA</summary><description>Given the following in a file to Pig, pig doesn't report any error, even if -c option is given: A = load 'x' as (u, v); B = foreach A generate $3; It's questionable whether to validate the query in batch mode as it doesn't contain any store/dump statement. However, if -c option is given, validation should be nevertheless performed.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>test.org.apache.pig.parser.TestQueryParser.java</file><file>test.org.apache.pig.test.TestBuiltin.java</file><file>test.org.apache.pig.test.TestGrunt.java</file><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file><file>test.org.apache.pig.test.TestNewPlanLogToPhyTranslationVisitor.java</file><file>test.org.apache.pig.test.TestPigServer.java</file><file>test.org.apache.pig.test.TestStreaming.java</file><file>test.org.apache.pig.test.TestUnionOnSchema.java</file></fixedFiles></bug><bug fixdate="2011-05-11 05:54:53" id="2058" opendate="2011-05-10 11:10:41"><buginformation><summary>[PIG-2058] Macro missing returns clause doesn't give a good error message - ASF JIRA</summary><description>For the following query: define test( out1,out2 ) { A = load 'x' as (u:int, v:int); $B = filter A by u &lt; 3 and v &lt; 20; } Pig gives the following error message: Syntax error,unexpected symbol at or near '{' Previously, it gives: mismatched input '{' expecting RETURNS The previous message is more meaningful.</description></buginformation><fixedFiles><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-05-12 07:12:41" id="2056" opendate="2011-05-10 08:06:44"><buginformation><summary>[PIG-2056] Jython error messages should show script name - ASF JIRA</summary><description>Instead of messages like &#13;
Traceback (most recent call last):&#13;
  File "&lt;iostream&gt;", line 12, in &lt;module&gt;&#13;
 It should display the script file name: &#13;
Traceback (most recent call last):&#13;
  File "test.py", line 12, in &lt;module&gt;</description></buginformation><fixedFiles><file>src.org.apache.pig.scripting.BoundScript.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file><file>test.org.apache.pig.test.TestScriptLanguage.java</file></fixedFiles></bug><bug fixdate="2011-05-10 08:18:05" id="2052" opendate="2011-05-09 07:12:34"><buginformation><summary>[PIG-2052] Ship guava.jar to backend - ASF JIRA</summary><description>We need to ship guava.jar to backend. GenericInvoker is using it.</description></buginformation><fixedFiles><file>src.org.apache.pig.impl.util.JarManager.java</file></fixedFiles></bug><bug fixdate="2011-05-06 11:52:40" id="2049" opendate="2011-05-06 08:04:29"><buginformation><summary>[PIG-2049] Pig should display TokenMgrError message consistently across all parsers - ASF JIRA</summary><description>For example, for org.apache.pig.tools.pigscript.parser.TokenMgrError, Pig logs &#13;
ERROR 1000: Error during parsing. Lexical error at line 5, column 0.&#13;
 But for org.apache.pig.tools.parameters.TokenMgrError, Pig logs &#13;
ERROR 2998: Unhandled internal error. Lexical error at line 10, column 0.&#13;
 Both should have error code 1000.</description></buginformation><fixedFiles><file>src.org.apache.pig.impl.util.LogUtils.java</file></fixedFiles></bug><bug fixdate="2011-05-07 12:56:50" id="2043" opendate="2011-05-05 07:07:14"><buginformation><summary>[PIG-2043] Ship antlr-runtime.jar to backend - ASF JIRA</summary><description>Following the discussion in PIG-2040, we want to make getSchemaFromString work in the backend, so we need to ship antlr-runtime.jar.</description></buginformation><fixedFiles><file>src.org.apache.pig.impl.util.JarManager.java</file></fixedFiles></bug><bug fixdate="2011-05-05 09:11:16" id="2041" opendate="2011-05-05 02:38:04"><buginformation><summary>[PIG-2041] Minicluster should make each run independent - ASF JIRA</summary><description>Minicluster will reuse ~/pigtest/conf/hadoop-site.xml. If something wrong in hadoop-site.xml, next test will also be affected. This leads to some mysterious test failures.</description></buginformation><fixedFiles><file>test.org.apache.pig.test.MiniCluster.java</file></fixedFiles></bug><bug fixdate="2011-05-05 09:09:31" id="2040" opendate="2011-05-04 10:47:28"><buginformation><summary>[PIG-2040] Move classloader from QueryParserDriver to PigContext - ASF JIRA</summary><description>After PIG-1775, mapreduce mode fail. The reason is we move classloader from LogicalPlanBuilder to QueryParserDriver, which will need antlr.jar, however, we don't ship antlr.jar to backend. It is better to move classloader to PigContext.</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.java</file><file>src.org.apache.pig.impl.PigContext.java</file><file>src.org.apache.pig.parser.QueryParserDriver.java</file></fixedFiles></bug><bug fixdate="2011-05-10 09:21:49" id="2039" opendate="2011-05-04 08:38:38"><buginformation><summary>[PIG-2039] IndexOutOfBounException for a case - ASF JIRA</summary><description>The following query gives an exception: a = load '1.txt' as (a0:int, a1:int, a2:int); b = group a by a0; c = foreach b { c1 = limit a 10; c2 = distinct c1.a1; c3 = distinct c1.a2; generate c2, c3;} ; store c into 'output'; 2011-05-04 12:36:01,720 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 2999: Unexpected internal error. Index: 0, Size: 0 Stack trace: java.lang.IndexOutOfBoundsException: Index: 0, Size: 0 at java.util.ArrayList.RangeCheck(ArrayList.java:547) at java.util.ArrayList.get(ArrayList.java:322) at org.apache.pig.newplan.logical.expression.ProjectExpression.getFieldSchema(ProjectExpression.java:279) at org.apache.pig.newplan.logical.relational.LOGenerate.getSchema(LOGenerate.java:88) at org.apache.pig.newplan.logical.visitor.SchemaAliasVisitor.validate(SchemaAliasVisitor.java:60) at org.apache.pig.newplan.logical.visitor.SchemaAliasVisitor.visit(SchemaAliasVisitor.java:104) at org.apache.pig.newplan.logical.relational.LOGenerate.accept(LOGenerate.java:240) at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75) at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50) at org.apache.pig.newplan.logical.visitor.SchemaAliasVisitor.visit(SchemaAliasVisitor.java:99) at org.apache.pig.newplan.logical.relational.LOForEach.accept(LOForEach.java:73) at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75) at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50) at org.apache.pig.PigServer$Graph.compile(PigServer.java:1664) at org.apache.pig.PigServer$Graph.validateQuery(PigServer.java:1615) at org.apache.pig.PigServer$Graph.registerQuery(PigServer.java:1586) at org.apache.pig.PigServer.registerQuery(PigServer.java:580) at org.apache.pig.tools.grunt.GruntParser.processPig(GruntParser.java:930) at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:386) at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:176) at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:152) at org.apache.pig.tools.grunt.Grunt.run(Grunt.java:76) at org.apache.pig.Main.run(Main.java:488) at org.apache.pig.Main.main(Main.java:109)</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.relational.LOForEach.java</file><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file></fixedFiles></bug><bug fixdate="2011-05-10 01:10:07" id="2038" opendate="2011-05-04 08:30:36"><buginformation><summary>[PIG-2038] Pig fails to parse empty tuple/map/bag constant - ASF JIRA</summary><description>Pig fails to parse the following query: a = foreach (load 'b') generate (); store a into 'output'; Error msg: Failed to parse: null Similar problem occurs for empty bag/map constant.</description></buginformation><fixedFiles><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file><file>test.org.apache.pig.test.TestMultiQuery.java</file></fixedFiles></bug><bug fixdate="2011-05-11 01:34:08" id="2035" opendate="2011-05-04 06:33:31"><buginformation><summary>[PIG-2035] Macro expansion doesn't handle multiple expansions of same macro inside another macro - ASF JIRA</summary><description>Here is the use case: &#13;
define test ( in, out, x ) returns c { &#13;
    a = load '$in' as (name, age, gpa);&#13;
    b = group a by gpa;&#13;
    $c = foreach b generate group, COUNT(a.$x);&#13;
    store $c into '$out';&#13;
};&#13;
&#13;
define test2( in, out ) returns x { &#13;
    $x = test( '$in', '$out', 'name' );&#13;
    $x = test( '$in', '$out.1', 'age' );&#13;
    $x = test( '$in', '$out.2', 'gpa' );&#13;
};&#13;
&#13;
x = test2('studenttab10k', 'myoutput');</description></buginformation><fixedFiles><file>src.org.apache.pig.parser.PigMacro.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-05-07 01:14:31" id="2033" opendate="2011-05-04 12:08:48"><buginformation><summary>[PIG-2033] Pig returns sucess for the failed Pig script - ASF JIRA</summary><description>Pig returns success when a Pig script fails but the count of failed MR jobs is zero.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.java</file></fixedFiles></bug><bug fixdate="2011-05-10 09:47:29" id="2030" opendate="2011-05-03 02:25:06"><buginformation><summary>[PIG-2030] Merged join/cogroup does not automatically ship loader - ASF JIRA</summary><description>The following script fail due to TableLoader class not found (If the jar is in classpath): &#13;
a = load '/user/pig/tests/data/zebra/singlefile/studentsortedtab10k' using org.apache.hadoop.zebra.pig.TableLoader('', 'sorted');&#13;
b = load '/user/pig/tests/data/zebra/singlefile/votersortedtab10k' using org.apache.hadoop.zebra.pig.TableLoader('', 'sorted');&#13;
g = cogroup a by $0, b by $0 using 'merge';&#13;
store g into '/user/pig/out/jianyong.1304374720/ZebraMapCogrp_1.out';&#13;
 If we use register, the error goes away. However, Pig always ship jars containing LoadFunc automatically. It should be the same for merged cogroup/join.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.java</file><file>test.org.apache.pig.test.TestMRCompiler.java</file></fixedFiles></bug><bug fixdate="2011-05-20 08:24:59" id="2029" opendate="2011-05-03 01:26:10"><buginformation><summary>[PIG-2029] Inconsistency in Pig Stats reports - ASF JIRA</summary><description>I have a Pig script which reports varying Stats for the same M/R job (same inputs). Sometimes the PigStats reports all the stats (such as Maps,Reduces,MaxMapTime,MinMapTime,AvgMapTime,MaxReduceTime, MinReduceTime and AvgReduceTime) for the M/R job as 0. Sometimes it reports it correctly. Enclosed are the stderr logs for 2 runs, you can notice that for Run 1 job_201103091134_556600 from Run 1; has 0 against all the columns whereas in Run 2, Hadoop job job_201104272229_75693 has some valid values. The actual Job Tracker link shows that they are non empty. This points to a bug in the interaction of the PigStats module with the Jobtracker. Run 1: Job Stats (time in seconds): JobId Maps Reduces MaxMapTime MinMapTIme AvgMapTime MaxReduceTime MinReduceTime AvgReduceTime Alias Feature Outputs job_201103091134_556458 160 100 552 191 368 1257 371 392 IN,SP10P,SP11P,SP12P,SP13P,SP16P,SP17P,SP18P,SP20P,SP21P,SP22P,SP23P,SP24P,SP26P,SP27P,SP28P,SP29P,SP30P,SP31P,SP32P,SP33P,SP34P,SP4P,SP6P,SP7P,SP8P,SP9P DISTINCT,MULTI_QUERY job_201103091134_556600 0 0 0 0 0 0 0 0 UNION5 MULTI_QUERY,MAP_ONLY /user/viraj/dir,, job_201103091134_556601 7 100 17 8 14 200 15 27 CNJOIN25,GNJOIN25,sampleNJOIN25 GROUP_BY,COMBINER job_201103091134_556602 0 0 0 0 0 0 0 0 CNJOIN3,GNJOIN3,sampleNJOIN3 GROUP_BY,COMBINER job_201103091134_556603 0 0 0 0 0 0 0 0 CNJOIN15,GNJOIN15,sampleNJOIN15 GROUP_BY,COMBINER job_201103091134_556604 2 100 13 7 10 34 13 31 CNJOIN19,GNJOIN19,sampleNJOIN19 GROUP_BY,COMBINER job_201103091134_556644 0 0 0 0 0 0 0 0 ONJOIN15 SAMPLER job_201103091134_556645 0 0 0 0 0 0 0 0 ONJOIN25 SAMPLER job_201103091134_556646 0 0 0 0 0 0 0 0 ONJOIN3 SAMPLER job_201103091134_556654 0 0 0 0 0 0 0 0 ONJOIN19 SAMPLER job_201103091134_556662 0 0 0 0 0 0 0 0 ONJOIN19 ORDER_BY,COMBINER .. Run 2: Job Stats (time in seconds): JobId Maps Reduces MaxMapTime MinMapTIme AvgMapTime MaxReduceTime MinReduceTime AvgReduceTime Alias Feature Outputs job_201104272229_75503 159 100 484 192 353 396 308 321 IN,SP10P,SP11P,SP12P,SP13P,SP16P,SP17P,SP18P,SP20P,SP21P,SP22P,SP23P,SP24P,SP26P,SP27P,SP28P,SP29P,SP30P,SP31P,SP32P,SP33P,SP34P,SP4P,SP6P,SP7P,SP8P,SP9P DISTINCT,MULTI_QUERY job_201104272229_75693 18 0 31 14 24 0 0 UNION5 MULTI_QUERY,MAP_ONLY /user/viraj/dir, job_201104272229_75694 7 100 34 13 22 46 20 25 CNJOIN25,GNJOIN25,sampleNJOIN25 GROUP_BY,COMBINER job_201104272229_75695 125 100 19 11 15 32 18 26 CNJOIN3,GNJOIN3,sampleNJOIN3 GROUP_BY,COMBINER job_201104272229_75698 1 100 12 12 12 13 9 11 CNJOIN15,GNJOIN15,sampleNJOIN15 GROUP_BY,COMBINER job_201104272229_75702 2 100 21 5 13 35 22 26 CNJOIN19,GNJOIN19,sampleNJOIN19 GROUP_BY,COMBINER job_201104272229_75724 1 1 4 4 4 11 11 11 ONJOIN15 SAMPLER job_201104272229_75725 0 0 0 0 0 0 0 ONJOIN25 SAMPLER job_201104272229_75726 6 1 8 6 8 24 24 24 ONJOIN3 SAMPLER job_201104272229_75729 0 0 0 0 0 0 0 ONJOIN19 SAMPLER job_201104272229_75752 1 100 5 5 5 12 9 11 ONJOIN19 ORDER_BY,COMBINER .. Viraj</description></buginformation><fixedFiles><file>src.org.apache.pig.tools.pigstats.JobStats.java</file><file>src.org.apache.pig.tools.pigstats.PigStatsUtil.java</file></fixedFiles></bug><bug fixdate="2011-05-04 01:12:27" id="2028" opendate="2011-05-02 11:37:12"><buginformation><summary>[PIG-2028] Speed up multiquery unit tests - ASF JIRA</summary><description>Switch TestMultiQueryBasic and TestMultiQuery to use LOCAL mode. The results on my laptop: Using Mini Cluster: TestMultiQueryBasic: 17 min 17 sec TestMultiQuery: 23 min 2 sec Using LOCAL mode: TestMultiQueryBasic: 4 min 17 sec TestMultiQuery: 5 min 51 sec</description></buginformation><fixedFiles><file>test.org.apache.pig.test.TestMultiQuery.java</file><file>test.org.apache.pig.test.TestMultiQueryBasic.java</file><file>test.org.apache.pig.test.Util.java</file></fixedFiles></bug><bug fixdate="2011-04-30 01:13:46" id="2018" opendate="2011-04-28 12:30:01"><buginformation><summary>[PIG-2018] NPE for co-group with group-by column having complex schema and different load functions for each input - ASF JIRA</summary><description>l1 = load 'x' using PigStorage(':') as (a : (i : int),b,c);&#13;
l2 = load 'x' as (a,b,c);&#13;
cg = cogroup l1 by a, l2 by a;&#13;
explain cg;&#13;
&#13;
Gives -&#13;
ERROR 1067: Unable to explain alias cg&#13;
&#13;
org.apache.pig.impl.logicalLayer.FrontendException: ERROR 1067: Unable to explain alias cg&#13;
        at org.apache.pig.PigServer.explain(PigServer.java:1075)&#13;
        at org.apache.pig.tools.grunt.GruntParser.explainCurrentBatch(GruntParser.java:381)&#13;
        at org.apache.pig.tools.grunt.GruntParser.processExplain(GruntParser.java:313)&#13;
        at org.apache.pig.tools.grunt.GruntParser.processExplain(GruntParser.java:276)&#13;
        at org.apache.pig.tools.pigscript.parser.PigScriptParser.Explain(PigScriptParser.java:665)&#13;
        at org.apache.pig.tools.pigscript.parser.PigScriptParser.parse(PigScriptParser.java:325)&#13;
        at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:176)&#13;
        at org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:152)&#13;
        at org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:90)&#13;
        at org.apache.pig.Main.run(Main.java:554)&#13;
        at org.apache.pig.Main.main(Main.java:109)&#13;
Caused by: java.lang.NullPointerException&#13;
        at org.apache.pig.newplan.logical.visitor.LineageFindRelVisitor.mapMatchLoadFuncToUid(LineageFindRelVisitor.java:528)&#13;
        at org.apache.pig.newplan.logical.visitor.LineageFindRelVisitor.visit(LineageFindRelVisitor.java:287)&#13;
        at org.apache.pig.newplan.logical.relational.LOCogroup.accept(LOCogroup.java:235)&#13;
        at org.apache.pig.newplan.DependencyOrderWalker.walk(DependencyOrderWalker.java:75)&#13;
        at org.apache.pig.newplan.PlanVisitor.visit(PlanVisitor.java:50)&#13;
        at org.apache.pig.newplan.logical.visitor.CastLineageSetter.&lt;init&gt;(CastLineageSetter.java:57)&#13;
        at org.apache.pig.PigServer$Graph.compile(PigServer.java:1683)&#13;
        at org.apache.pig.PigServer$Graph.compile(PigServer.java:1659)&#13;
        at org.apache.pig.PigServer$Graph.access$200(PigServer.java:1389)&#13;
        at org.apache.pig.PigServer.buildStorePlan(PigServer.java:1277)&#13;
        at org.apache.pig.PigServer.explain(PigServer.java:1038)&#13;
        ... 10 more</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.visitor.LineageFindRelVisitor.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file></fixedFiles></bug><bug fixdate="2011-05-03 02:42:18" id="2016" opendate="2011-04-26 09:56:34"><buginformation><summary>[PIG-2016] -dot option does not work with explain and new logical plan - ASF JIRA</summary><description>If you specify -dot in explain, it is supposed to produce a file with the graphs in .dot format. While the physical plan and map reduce plan are correctly output in .dot format, the new logical plan is still output in text format.</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.DotPlanDumper.java</file><file>src.org.apache.pig.newplan.PlanDumper.java</file><file>src.org.apache.pig.newplan.logical.DotLOPrinter.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalPlan.java</file><file>test.org.apache.pig.test.TestEvalPipelineLocal.java</file></fixedFiles></bug><bug fixdate="2011-04-30 12:05:51" id="2015" opendate="2011-04-26 09:53:55"><buginformation><summary>[PIG-2015] Explain writes out logical plan twice - ASF JIRA</summary><description>Running explain on a script writes out the logical plan twice, the physical plan once, and the map reduce plan once.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file></fixedFiles></bug><bug fixdate="2011-05-12 11:01:28" id="2014" opendate="2011-04-26 03:35:38"><buginformation><summary>[PIG-2014] SAMPLE shouldn't be pushed up - ASF JIRA</summary><description>Consider the following code: &#13;
tfidf_all = LOAD '$TFIDF' AS (doc_id:chararray, token:chararray, weight:double);&#13;
grouped   = GROUP tfidf_all BY doc_id;&#13;
vectors   = FOREACH grouped GENERATE group AS doc_id, tfidf_all.(token, weight) AS vector;&#13;
DUMP vectors;&#13;
 This, of course, runs just fine. In a real example, tfidf_all contains 1,428,280 records. The reduce output records should be exactly the number of documents, which turn out to be 18,863 in this case. All well and good. The strangeness comes when you add a SAMPLE command: &#13;
sampled = SAMPLE vectors 0.0012;&#13;
DUMP sampled;&#13;
 Running this results in 1,513 reduce output records. The reduce output records be much much closer to 22 or 23 records (eg. 0.0012*18863). Evidently, Pig rewrites SAMPLE into filter, and then pushes that filter in front of the group. It shouldn't push that filter since the UDF is non-deterministic. Quick fix: If you add "-t PushUpFilter" to your command line when invoking pig this won't happen.</description></buginformation><fixedFiles><file>src.org.apache.pig.builtin.Nondeterministic.java</file><file>src.org.apache.pig.builtin.RANDOM.java</file><file>src.org.apache.pig.newplan.logical.optimizer.SchemaResetter.java</file><file>src.org.apache.pig.newplan.logical.optimizer.UidResetter.java</file><file>src.org.apache.pig.newplan.logical.rules.FilterAboveForeach.java</file><file>src.org.apache.pig.newplan.logical.rules.OptimizerUtils.java</file><file>src.org.apache.pig.newplan.logical.rules.PushDownForEachFlatten.java</file><file>src.org.apache.pig.newplan.logical.rules.PushUpFilter.java</file><file>test.org.apache.pig.test.TestNewPlanFilterAboveForeach.java</file><file>test.org.apache.pig.test.TestNewPlanFilterRule.java</file><file>test.org.apache.pig.test.TestNewPlanPushDownForeachFlatten.java</file></fixedFiles></bug><bug fixdate="2011-05-09 11:52:16" id="2012" opendate="2011-04-23 03:35:56"><buginformation><summary>[PIG-2012] Comments at the begining of the file throws off line numbers in errors - ASF JIRA</summary><description>The preprocessor does not appear to be handling leading comments properly when calculating line numbers for error messages. In the attached script, the error is reported to be on line 7. It is actually on line 10.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.parser.PigMacro.java</file><file>src.org.apache.pig.parser.PigParserNode.java</file><file>src.org.apache.pig.parser.PigParserNodeAdaptor.java</file><file>src.org.apache.pig.parser.QueryParserDriver.java</file><file>src.org.apache.pig.parser.QueryParserUtils.java</file><file>src.org.apache.pig.parser.SourceLocation.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-04-22 07:06:48" id="2007" opendate="2011-04-21 11:04:25"><buginformation><summary>[PIG-2007] Parsing error when map key referred directly from udf in nested foreach - ASF JIRA</summary><description>The below script when executed with version 0.9 fails with parsing error. &#13;
 ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1000: Error during parsing. &lt;line 2, column 15&gt; mismatched input '{' expecting GENERATE&#13;
 Script1 &#13;
register myudf.jar;&#13;
A = load 'test.txt' using PigStorage() as (a:int,b:chararray);&#13;
B1 = foreach A {&#13;
        C = test.TOMAP('key1',$1)#'key1';&#13;
        generate C as C;&#13;
}&#13;
 The above happens when, in a nested foreach i refer to a map key directly from a udf result The same would work if one executes without the nested foreach. &#13;
register myudf.jar;&#13;
A = load 'test.txt' using PigStorage() as (a:int,b:chararray);&#13;
B1 = foreach A generate test.TOMAP('key1',$1)#'key1';&#13;
dump B1;&#13;
 Script1 works well with 0.8.</description></buginformation><fixedFiles><file>test.org.apache.pig.parser.TestLogicalPlanGenerator.java</file></fixedFiles></bug><bug fixdate="2011-04-26 07:13:41" id="2006" opendate="2011-04-21 01:22:07"><buginformation><summary>[PIG-2006] Regression: NPE when Pig processes an empty script file - ASF JIRA</summary><description>If a pig script file is empty and supplied as input for Pig (using -f option), an NPE is thrown. Stacktrace: java.lang.NullPointerException at java.util.regex.Matcher.getTextLength(Matcher.java:1140) at java.util.regex.Matcher.reset(Matcher.java:291) at java.util.regex.Matcher.&lt;init&gt;(Matcher.java:211) at java.util.regex.Pattern.matcher(Pattern.java:888) at org.apache.pig.scripting.ScriptEngine$SupportedScriptLang.accepts(ScriptEngine.java:89) at org.apache.pig.scripting.ScriptEngine.getSupportedScriptLang(ScriptEngine.java:163) at org.apache.pig.Main.determineScriptType(Main.java:892) at org.apache.pig.Main.run(Main.java:378) at org.apache.pig.Main.main(Main.java:108) This seems related Jython support in 0.9.</description></buginformation><fixedFiles><file>src.org.apache.pig.scripting.ScriptEngine.java</file><file>test.org.apache.pig.test.TestPigRunner.java</file></fixedFiles></bug><bug fixdate="2011-05-03 01:24:04" id="1998" opendate="2011-04-18 09:34:34"><buginformation><summary>[PIG-1998] Allow macro to return void - ASF JIRA</summary><description>Pig macro is allowed to not have output alias. But this property isn't clear from macro definition and macro invocation (macro inline). Here we propose to make it clear: 1. If a macro doesn't output any alias, it must specify void as return value. For example:   &#13;
define mymacro(...) returns void {&#13;
   ... ...&#13;
};&#13;
 2. If a macro doesn't output any alias, it must be invoked without return value. For example, to invoke above macro, just specify: &#13;
mymacro(...);&#13;
 3. Any non-void return alias in the macro definition must exist in the macro body and be prefixed with $. For example:   &#13;
define mymacro(...) returns B {&#13;
   ... ...&#13;
   $B = filter ...;&#13;
};</description></buginformation><fixedFiles><file>src.org.apache.pig.parser.PigMacro.java</file><file>src.org.apache.pig.parser.QueryParserDriver.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-04-25 10:15:26" id="1981" opendate="2011-04-08 06:51:03"><buginformation><summary>[PIG-1981] LoadPushDown.pushProjection should pass alias in addition to position - ASF JIRA</summary><description>Currently pushProjection(RequiredFieldList requiredFieldList) requiredFieldList only contains position. It is better that we also provide alias whenever available.</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.rules.ColumnPruneVisitor.java</file><file>test.org.apache.pig.test.TestPruneColumn.java</file></fixedFiles></bug><bug fixdate="2011-05-12 10:26:06" id="1938" opendate="2011-03-28 01:02:13"><buginformation><summary>[PIG-1938] support project-range as udf argument - ASF JIRA</summary><description>With changes in PIG-1693, project-range ('..') is supported in all use cases where '*' (project-star) is supported, except as udf argument. To be consistent with usage of project-star, project-range should be supported as udf argument as well.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.java</file><file>src.org.apache.pig.builtin.TOBAG.java</file><file>src.org.apache.pig.newplan.logical.optimizer.ProjectionPatcher.java</file><file>src.org.apache.pig.newplan.logical.visitor.ProjStarInUdfExpander.java</file><file>src.org.apache.pig.newplan.logical.visitor.ProjectStarExpander.java</file><file>src.org.apache.pig.newplan.logical.visitor.ProjectStarExpanderUtil.java</file><file>test.org.apache.pig.test.TestNewPlanFilterAboveForeach.java</file><file>test.org.apache.pig.test.TestProjectRange.java</file><file>test.org.apache.pig.test.TestProjectStarRangeInUdf.java</file><file>test.org.apache.pig.test.Util.java</file></fixedFiles></bug><bug fixdate="2011-03-11 08:09:40" id="1874" opendate="2011-03-01 09:38:54"><buginformation><summary>[PIG-1874] Make PigServer work in a multithreading environment - ASF JIRA</summary><description>This means that PigServers should work if one creates separate PigServer instances for each thread (PigServers are not synchronized).</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.POStatus.java</file><file>src.org.apache.pig.impl.PigContext.java</file><file>src.org.apache.pig.impl.util.UDFContext.java</file><file>src.org.apache.pig.scripting.BoundScript.java</file><file>test.org.apache.pig.test.TestScriptLanguage.java</file><file>test.org.apache.pig.test.utils.UDFContextTestEvalFunc3.java</file></fixedFiles></bug><bug fixdate="2011-03-01 10:55:49" id="1829" opendate="2011-01-27 08:48:47"><buginformation><summary>[PIG-1829] "0" value seen in PigStat's map/reduce runtime, even when the job is successful - ASF JIRA</summary><description>Pig runtime calls JobClient.getMapTaskReports(jobId) and JobClient.getReduceTaskReports(jobId) to get statistics about numbers of maps/reducers, as well as max/min/avg time of these tasks. But from time to time, these calls return empty lists. When that happens pig is reports 0 values for the stats. The jobtracker keeps the stats information only for a limited duration based on the configuration parameters mapred.jobtracker.completeuserjobs.maximum and mapred.job.tracker.retiredjobs.cache.size. Since pig collects the stats after jobs have finished running, it is possible that the stats for the initial jobs are no longer available. To have better chances of getting the stats, it should be collected as soon as the job is over.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.java</file><file>src.org.apache.pig.tools.pigstats.PigStatsUtil.java</file><file>src.org.apache.pig.tools.pigstats.SimplePigStats.java</file></fixedFiles></bug><bug fixdate="2011-01-24 01:33:07" id="1809" opendate="2011-01-18 03:27:00"><buginformation><summary>[PIG-1809] TOMAP builtin function - ASF JIRA</summary><description>While doing some testing, I needed a function that generated a map. I created TOMAP that is similar to TOTUPLE and TOBAG and want to contribute it to builtin in case it is useful to others</description></buginformation><fixedFiles><file>src.org.apache.pig.builtin.TOMAP.java</file><file>test.org.apache.pig.test.TestBuiltin.java</file></fixedFiles></bug><bug fixdate="2011-01-19 06:29:09" id="1806" opendate="2011-01-14 08:33:30"><buginformation><summary>[PIG-1806] Modify embedded Pig API for usability - ASF JIRA</summary><description>bind methods. Currently, to explicitly bind variables to parameters, the variable type must be string: &#13;
public BoundScript bind(Map&lt;String, String&gt; vars) throws IOException {...}&#13;
 User needs explicitly convert variables to strings before passing them in. We propose to change the method signature so user does not need to do the conversion: &#13;
public BoundScript bind(Map&lt;String, Object&gt; vars) throws IOException {...}&#13;
 Internally Pig uses toString() method to convert variables to strings. fs method. Current Pig.fs(...) method doesn't return any value. Since this method just turns around to call FsShell.run() which has a return code, we should pass this return code to the user; &#13;
public static int fs(String cmd) throws IOException {...}</description></buginformation><fixedFiles><file>src.org.apache.pig.scripting.Pig.java</file><file>src.org.apache.pig.scripting.ScriptEngine.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file><file>test.org.apache.pig.test.TestScriptLanguage.java</file></fixedFiles></bug><bug fixdate="2011-05-07 01:16:30" id="1775" opendate="2010-12-17 06:18:03"><buginformation><summary>[PIG-1775] Removal of old logical plan - ASF JIRA</summary><description>The new logical plan will only be used and the old logical plan will be removed once the new one is stable enough. It is scheduled for the 0.9 release.</description></buginformation><fixedFiles><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.PigStorageSchema.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.impl.logicalLayer.ExpressionOperator.java</file><file>src.org.apache.pig.impl.logicalLayer.LOAdd.java</file><file>src.org.apache.pig.impl.logicalLayer.LOAnd.java</file><file>src.org.apache.pig.impl.logicalLayer.LOBinCond.java</file><file>src.org.apache.pig.impl.logicalLayer.LOCast.java</file><file>src.org.apache.pig.impl.logicalLayer.LOCogroup.java</file><file>src.org.apache.pig.impl.logicalLayer.LOCross.java</file><file>src.org.apache.pig.impl.logicalLayer.LODefine.java</file><file>src.org.apache.pig.impl.logicalLayer.LOEqual.java</file><file>src.org.apache.pig.impl.logicalLayer.LOForEach.java</file><file>src.org.apache.pig.impl.logicalLayer.LOGenerate.java</file><file>src.org.apache.pig.impl.logicalLayer.LOIsNull.java</file><file>src.org.apache.pig.impl.logicalLayer.LOJoin.java</file><file>src.org.apache.pig.impl.logicalLayer.LOLesserThan.java</file><file>src.org.apache.pig.impl.logicalLayer.LOLimit.java</file><file>src.org.apache.pig.impl.logicalLayer.LONotEqual.java</file><file>src.org.apache.pig.impl.logicalLayer.LOOr.java</file><file>src.org.apache.pig.impl.logicalLayer.LOPrinter.java</file><file>src.org.apache.pig.impl.logicalLayer.LOProject.java</file><file>src.org.apache.pig.impl.logicalLayer.LORegexp.java</file><file>src.org.apache.pig.impl.logicalLayer.LOSplit.java</file><file>src.org.apache.pig.impl.logicalLayer.LOSplitOutput.java</file><file>src.org.apache.pig.impl.logicalLayer.LOStore.java</file><file>src.org.apache.pig.impl.logicalLayer.LOStream.java</file><file>src.org.apache.pig.impl.logicalLayer.LOUserFunc.java</file><file>src.org.apache.pig.impl.logicalLayer.LogicalOperator.java</file><file>src.org.apache.pig.impl.logicalLayer.LogicalPlanCloner.java</file><file>src.org.apache.pig.impl.logicalLayer.PlanSetter.java</file><file>src.org.apache.pig.impl.logicalLayer.ProjectStarTranslator.java</file><file>src.org.apache.pig.impl.logicalLayer.ProjectionMapRemover.java</file><file>src.org.apache.pig.impl.logicalLayer.RelationalOperator.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.ImplicitSplitInserter.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.LogicalOptimizer.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.LogicalTransformer.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.OpLimitOptimizer.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.PartitionFilterOptimizer.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.PruneColumns.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.PushDownForeachFlatten.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.SchemaCalculator.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.SchemaRemover.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.TypeCastInserter.java</file><file>src.org.apache.pig.impl.logicalLayer.schema.Schema.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.InputOutputFileValidator.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.InputOutputFileVisitor.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.LogicalPlanValidationExecutor.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.SchemaAliasValidator.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.SchemaAliasVisitor.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.TypeCheckingValidator.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.TypeCheckingVisitor.java</file><file>src.org.apache.pig.impl.logicalLayer.validators.UnionOnSchemaSetException.java</file><file>src.org.apache.pig.impl.util.Utils.java</file><file>src.org.apache.pig.newplan.logical.Util.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalSchema.java</file><file>src.org.apache.pig.parser.QueryParserDriver.java</file><file>src.org.apache.pig.scripting.js.JsFunction.java</file><file>src.org.apache.pig.scripting.jython.JythonFunction.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file><file>src.org.apache.pig.tools.grunt.Grunt.java</file><file>test.org.apache.pig.test.OpLimitOptimizerPrinter.java</file><file>test.org.apache.pig.test.TestAccumulator.java</file><file>test.org.apache.pig.test.TestCollectedGroup.java</file><file>test.org.apache.pig.test.TestCombiner.java</file><file>test.org.apache.pig.test.TestConversions.java</file><file>test.org.apache.pig.test.TestFilterSimplification.java</file><file>test.org.apache.pig.test.TestForEachNestedPlan.java</file><file>test.org.apache.pig.test.TestForEachStar.java</file><file>test.org.apache.pig.test.TestGroupConstParallel.java</file><file>test.org.apache.pig.test.TestImplicitSplit.java</file><file>test.org.apache.pig.test.TestInputOutputFileValidator.java</file><file>test.org.apache.pig.test.TestJobSubmission.java</file><file>test.org.apache.pig.test.TestJoin.java</file><file>test.org.apache.pig.test.TestLoad.java</file><file>test.org.apache.pig.test.TestLogToPhyCompiler.java</file><file>test.org.apache.pig.test.TestLogicalOptimizer.java</file><file>test.org.apache.pig.test.TestLogicalPlanBuilder.java</file><file>test.org.apache.pig.test.TestMRCompiler.java</file><file>test.org.apache.pig.test.TestMapSideCogroup.java</file><file>test.org.apache.pig.test.TestMergeJoin.java</file><file>test.org.apache.pig.test.TestMergeJoinOuter.java</file><file>test.org.apache.pig.test.TestMultiQuery.java</file><file>test.org.apache.pig.test.TestNewPlanFilterAboveForeach.java</file><file>test.org.apache.pig.test.TestNewPlanFilterRule.java</file><file>test.org.apache.pig.test.TestNewPlanImplicitSplit.java</file><file>test.org.apache.pig.test.TestNewPlanPruneMapKeys.java</file><file>test.org.apache.pig.test.TestNewPlanPushDownForeachFlatten.java</file><file>test.org.apache.pig.test.TestOperatorPlan.java</file><file>test.org.apache.pig.test.TestOptimizeLimit.java</file><file>test.org.apache.pig.test.TestPOCast.java</file><file>test.org.apache.pig.test.TestPartitionFilterOptimization.java</file><file>test.org.apache.pig.test.TestPartitionFilterPushDown.java</file><file>test.org.apache.pig.test.TestPigScriptParser.java</file><file>test.org.apache.pig.test.TestPigServer.java</file><file>test.org.apache.pig.test.TestProjectRange.java</file><file>test.org.apache.pig.test.TestProjectStarExpander.java</file><file>test.org.apache.pig.test.TestProjectionMap.java</file><file>test.org.apache.pig.test.TestPushDownForeachFlatten.java</file><file>test.org.apache.pig.test.TestPushUpFilter.java</file><file>test.org.apache.pig.test.TestRelationToExprProject.java</file><file>test.org.apache.pig.test.TestRelevantFields.java</file><file>test.org.apache.pig.test.TestRequiredFields.java</file><file>test.org.apache.pig.test.TestRewire.java</file><file>test.org.apache.pig.test.TestSampleOptimizer.java</file><file>test.org.apache.pig.test.TestSchema.java</file><file>test.org.apache.pig.test.TestSchemaParser.java</file><file>test.org.apache.pig.test.TestScriptUDF.java</file><file>test.org.apache.pig.test.TestSecondarySort.java</file><file>test.org.apache.pig.test.TestStore.java</file><file>test.org.apache.pig.test.TestStoreInstances.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidator.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNoSchema.java</file><file>test.org.apache.pig.test.TestTypedMap.java</file><file>test.org.apache.pig.test.TestUnionOnSchema.java</file><file>test.org.apache.pig.test.TypeGraphPrinter.java</file><file>test.org.apache.pig.test.Util.java</file><file>test.org.apache.pig.test.utils.dotGraph.DotGraphVisitor.java</file><file>test.org.apache.pig.test.utils.planComparer.LogicalPlanComparer.java</file></fixedFiles></bug><bug fixdate="2011-01-25 05:50:01" id="1769" opendate="2010-12-15 05:36:29"><buginformation><summary>[PIG-1769] Consistency for HBaseStorage - ASF JIRA</summary><description>In our load statement we are allowed to prefix the table name with "hbase://" but when we call store it throws an exception unless we remove hbase:// from the table name: this works: store raw into 'piggytest2' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('content2:field1 anchor2:field1a anchor2:field2a'); this won't store raw into 'hbase://piggytest2' Exception: Caused by: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: hbase://piggytest2_logs Would be nice to be able to prefix the store with hbase:// so it's consistent with the load syntax</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.java</file><file>src.org.apache.pig.backend.hadoop.hbase.HBaseStorage.java</file><file>test.org.apache.pig.test.TestHBaseStorage.java</file></fixedFiles></bug><bug fixdate="2010-12-09 06:39:33" id="1757" opendate="2010-12-07 11:04:48"><buginformation><summary>[PIG-1757] After split combination, the number of maps may vary slightly - ASF JIRA</summary><description>The split combination, introduced in 0.8 by PIG-1518, may see small variations in number of maps. For instance, PigMix2's L4 query experiences a variation of 901 or 902 maps in a test cluster. The reason is that the BlockLocation's getHosts method, used in FileInputFormat's spli generation, returns a list of hosts that hold the block. However the ordering of the list is not deterministic. Pig's split combination is not immune to such a random ordering since the combination decision is based upon the hosts that hold as many data local to a map as possible, and there is no specific tie-breaking rule to force a particular ordering. In some benchmarking or performance baselining tests, these variations, however small they are, might not be desirable. One solution is to sort the host lists from the component splits so as to get consistent number of maps. I suspect that other split combination techniques that make use of the data host info to maximize the data locality in each map, like CombineFileInputFormat, might have had the similar variations of number of maps.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil.java</file></fixedFiles></bug><bug fixdate="2010-12-23 02:18:59" id="1755" opendate="2010-12-06 02:35:19"><buginformation><summary>[PIG-1755] Clean up duplicated code in Physical Operators - ASF JIRA</summary><description>A lot of the getNext() implementations in PhysicalOperators is copy-pasted, with only the method signatures and casts changing. Shorter code leads to less bugs and is easier to read.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.PhysicalOperator.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Add.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ConstantExpression.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Divide.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.EqualToExpr.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.ExpressionOperator.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.GTOrEqualToExpr.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.GreaterThanExpr.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.LTOrEqualToExpr.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.LessThanExpr.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Mod.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Multiply.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.NotEqualToExpr.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POBinCond.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POIsNull.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.Subtract.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCollectedGroup.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPartitionRearrange.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPreCombinerLocalRearrange.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort.java</file><file>src.org.apache.pig.data.DataType.java</file></fixedFiles></bug><bug fixdate="2011-01-21 09:58:39" id="1749" opendate="2010-11-24 08:30:49"><buginformation><summary>[PIG-1749] Update Pig parser so that function arguments can contain newline characters - ASF JIRA</summary><description>We want to add this feature so that users can put long function argument strings in multiple lines. PIG-1748 depends on this.</description></buginformation><fixedFiles><file>test.org.apache.pig.parser.TestQueryParser.java</file><file>test.org.apache.pig.test.TestParamSubPreproc.java</file></fixedFiles></bug><bug fixdate="2011-01-31 09:19:32" id="1748" opendate="2010-11-24 08:27:21"><buginformation><summary>[PIG-1748] Add load/store function AvroStorage for avro data - ASF JIRA</summary><description>We want to use Pig to process arbitrary Avro data and store results as Avro files. AvroStorage() extends two PigFuncs: LoadFunc and StoreFunc. Due to discrepancies of Avro and Pig data models, AvroStorage has: 1. Limited support for "record": we do not support recursively defined record because the number of fields in such records is data dependent. 2. Limited support for "union": we only accept nullable union like ["null", "some-type"]. For simplicity, we also make the following assumptions: If the input directory is a leaf directory, then we assume Avro data files in it have the same schema; If the input directory contains sub-directories, then we assume Avro data files in all sub-directories have the same schema. AvroStorage takes no input parameters when used as a LoadFunc (except for "debug [debug-level]"). Users can provide parameters to AvroStorage when used as a StoreFunc. If they don't, Avro schema of output data is derived from its Pig schema. Detailed documentation can be found in http://linkedin.jira.com/wiki/display/HTOOLS/AvroStorage+-+Pig+support+for+Avro+data</description></buginformation><fixedFiles><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.ASCommons.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.ASFsInput.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.ASLog.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.AvroSchema2Pig.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.AvroSchemaManager.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.AvroStorage.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.AvroStorageUtils.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigAvroDatumReader.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigAvroDatumWriter.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigAvroInputFormat.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigAvroOutputFormat.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigAvroRecordReader.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigAvroRecordWriter.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.avro.PigSchema2Avro.java</file></fixedFiles></bug><bug fixdate="2010-12-01 12:31:33" id="1747" opendate="2010-11-24 07:02:38"><buginformation><summary>[PIG-1747] pattern match classes for matching patterns in physical plan - ASF JIRA</summary><description>Map-reduce plan optimization phase of query planning in pig uses several visitors. Each of these visitors use custom code to identify patterns in physical plan to determine if the optimization should be applied. Having pattern match utility classes that works with physical plan will make writing new visitors easier.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PatternNode.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.plans.PatternPlan.java</file><file>test.org.apache.pig.test.TestPhyPatternMatch.java</file></fixedFiles></bug><bug fixdate="2011-02-03 08:03:28" id="1717" opendate="2010-11-11 03:41:37"><buginformation><summary>[PIG-1717] pig needs to call setPartitionFilter if schema is null but getPartitionKeys is not - ASF JIRA</summary><description>I'm writing a loader that works with hive style partitioning e.g. /logs/type1/daydate=2010-11-01 The loader does not know the schema upfront and this is something that the user adds in the script using the AS clause. The problem is that this user defined schema is not available to the loader, so the loader cannot return any schema, the Loader does know what the partition keys are and pig needs in some way to know about these partition keys. Currently if the schema is null pig never calls the LoadMetaData:getPartitionKeys method or the setPartitionFilter method.</description></buginformation><fixedFiles><file>src.org.apache.pig.impl.logicalLayer.LOLoad.java</file><file>src.org.apache.pig.impl.util.Utils.java</file><file>src.org.apache.pig.newplan.logical.relational.LOLoad.java</file><file>test.org.apache.pig.test.TestLOLoadDeterminedSchema.java</file><file>test.org.apache.pig.test.utils.ScriptSchemaTestLoader.java</file></fixedFiles></bug><bug fixdate="2010-11-03 08:59:11" id="1707" opendate="2010-11-02 07:05:07"><buginformation><summary>[PIG-1707] Allow pig build to pull from alternate maven repo to enable building against newer hadoop versions - ASF JIRA</summary><description>Currently pig build only pulls jar from http://repo1.maven.org/maven2/ for the dependencies. THis restricts the build to only released hadoop versions (and other dependencies). It would be good if pig build is configurable to use any maven repo url (with default being maven.org repo).</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file></fixedFiles></bug><bug fixdate="2010-10-29 11:32:21" id="1696" opendate="2010-10-23 09:26:51"><buginformation><summary>[PIG-1696] Performance: Use System.arraycopy() instead of manually copying the bytes while reading the data - ASF JIRA</summary><description>System.arraycopy() is said to be faster as compared to iterating over bytes and copying them over as it is implemented natively in JVM. Since every single byte read through PigStorage() will go through this code-path, this will have a performance impact.</description></buginformation><fixedFiles><file>src.org.apache.pig.data.DataByteArray.java</file></fixedFiles></bug><bug fixdate="2011-01-08 09:14:44" id="1675" opendate="2010-10-11 02:56:03"><buginformation><summary>[PIG-1675] Suggest to allow PigServer can register pig script from InputStream - ASF JIRA</summary><description>Currently, Pig only allow users to register script from file. Although it satisfy most people's requirements, sometimes people hope to build pig script dynamically using code, then they need to create temp file for the script they build. So here I suggest to allow PigServer be able to register pig script from InputStream. InputStream is a more general type than File, pig script can been from file (FileInputStream) or from in-memory (ByteArrayInputStream) even it can been from remote machines (SocketInputStream) Here's a blog which explains why using InputStream is better than using File in interface http://java.dzone.com/articles/using-files-your-interfaces-0 So I suggest to add the following 4 methods in PigServer: &#13;
public void registerScript(InputStream in) throws IOException&#13;
public void registerScript(InputStream in, Map&lt;String,String&gt; params) throws IOException&#13;
public void registerScript(InputStream in, List&lt;String&gt; paramsFiles) throws IOException&#13;
public void registerScript(InputStream in, Map&lt;String,String&gt; params,List&lt;String&gt; paramsFiles) throws IOException</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>test.org.apache.pig.test.TestPigServer.java</file></fixedFiles></bug><bug fixdate="2011-03-18 12:34:20" id="1618" opendate="2010-09-17 04:55:42"><buginformation><summary>[PIG-1618] Switch to new parser generator technology - ASF JIRA</summary><description>There are many bugs in Pig related to the parser, particularly to bad error messages. After review of Java CC we feel these will be difficult to address using that tool. Also, the .jjt files used by JavaCC are hard to understand and maintain. ANTLR is being reviewed as the most likely choice to move to, but other parsers will be reviewed as well. This JIRA will act as an umbrella issue for other parser issues.</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.SortInfoSetter.java</file><file>src.org.apache.pig.StandAloneParser.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.HExecutionEngine.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POMergeJoin.java</file><file>src.org.apache.pig.impl.PigContext.java</file><file>src.org.apache.pig.impl.logicalLayer.LOCogroup.java</file><file>src.org.apache.pig.impl.logicalLayer.LOJoin.java</file><file>src.org.apache.pig.impl.logicalLayer.ProjectFixerUpper.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.PushDownForeachFlatten.java</file><file>src.org.apache.pig.impl.logicalLayer.optimizer.PushUpFilter.java</file><file>src.org.apache.pig.impl.logicalLayer.schema.Schema.java</file><file>src.org.apache.pig.impl.plan.OperatorPlan.java</file><file>src.org.apache.pig.impl.util.MultiMap.java</file><file>src.org.apache.pig.newplan.BaseOperatorPlan.java</file><file>src.org.apache.pig.newplan.OperatorPlan.java</file><file>src.org.apache.pig.newplan.OperatorSubPlan.java</file><file>src.org.apache.pig.newplan.logical.LogicalExpPlanMigrationVistor.java</file><file>src.org.apache.pig.newplan.logical.LogicalPlanMigrationVistor.java</file><file>src.org.apache.pig.newplan.logical.Util.java</file><file>src.org.apache.pig.newplan.logical.expression.BinCondExpression.java</file><file>src.org.apache.pig.newplan.logical.expression.ConstantExpression.java</file><file>src.org.apache.pig.newplan.logical.expression.DereferenceExpression.java</file><file>src.org.apache.pig.newplan.logical.expression.ExpToPhyTranslationVisitor.java</file><file>src.org.apache.pig.newplan.logical.expression.LogicalExpressionPlan.java</file><file>src.org.apache.pig.newplan.logical.expression.LogicalExpressionVisitor.java</file><file>src.org.apache.pig.newplan.logical.expression.MapLookupExpression.java</file><file>src.org.apache.pig.newplan.logical.expression.ProjectExpression.java</file><file>src.org.apache.pig.newplan.logical.expression.ScalarExpression.java</file><file>src.org.apache.pig.newplan.logical.expression.UserFuncExpression.java</file><file>src.org.apache.pig.newplan.logical.optimizer.AllExpressionVisitor.java</file><file>src.org.apache.pig.newplan.logical.relational.LOCogroup.java</file><file>src.org.apache.pig.newplan.logical.relational.LOGenerate.java</file><file>src.org.apache.pig.newplan.logical.relational.LOInnerLoad.java</file><file>src.org.apache.pig.newplan.logical.relational.LOJoin.java</file><file>src.org.apache.pig.newplan.logical.relational.LOSort.java</file><file>src.org.apache.pig.newplan.logical.relational.LOStore.java</file><file>src.org.apache.pig.newplan.logical.relational.LOUnion.java</file><file>src.org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalPlan.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalRelationalOperator.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalSchema.java</file><file>src.org.apache.pig.newplan.logical.rules.ColumnPruneHelper.java</file><file>src.org.apache.pig.newplan.logical.rules.ConstExpEvaluator.java</file><file>src.org.apache.pig.newplan.logical.rules.ImplicitSplitInserter.java</file><file>src.org.apache.pig.newplan.logical.visitor.CastLineageSetter.java</file><file>src.org.apache.pig.newplan.logical.visitor.ColumnAliasConversionVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.LineageFindRelVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.ProjectStarExpander.java</file><file>src.org.apache.pig.newplan.logical.visitor.ScalarVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.SchemaAliasVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.SortInfoSetter.java</file><file>src.org.apache.pig.newplan.logical.visitor.TypeCheckingExpVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.TypeCheckingRelVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.UnionOnSchemaSetter.java</file><file>src.org.apache.pig.newplan.visitor.SortInfoSetter.java</file><file>src.org.apache.pig.newplan.visitor.UnionOnSchemaSetter.java</file><file>src.org.apache.pig.parser.AntlrNoCaseFileStream.java</file><file>src.org.apache.pig.parser.AntlrNoCaseStringStream.java</file><file>src.org.apache.pig.parser.DuplicatedSchemaAliasException.java</file><file>src.org.apache.pig.parser.FunctionType.java</file><file>src.org.apache.pig.parser.InvalidCommandException.java</file><file>src.org.apache.pig.parser.InvalidPathException.java</file><file>src.org.apache.pig.parser.InvalidScalarProjectionException.java</file><file>src.org.apache.pig.parser.LogicalPlanBuilder.java</file><file>src.org.apache.pig.parser.NonProjectExpressionException.java</file><file>src.org.apache.pig.parser.ParserException.java</file><file>src.org.apache.pig.parser.ParserValidationException.java</file><file>src.org.apache.pig.parser.PlanGenerationFailureException.java</file><file>src.org.apache.pig.parser.QueryParserDriver.java</file><file>src.org.apache.pig.parser.QueryParserFileStream.java</file><file>src.org.apache.pig.parser.QueryParserStreamUtil.java</file><file>src.org.apache.pig.parser.QueryParserStringStream.java</file><file>src.org.apache.pig.parser.QueryParserUtils.java</file><file>src.org.apache.pig.parser.StreamingCommandUtils.java</file><file>src.org.apache.pig.parser.UndefinedAliasException.java</file><file>src.org.apache.pig.pen.AugmentBaseDataVisitor.java</file><file>src.org.apache.pig.pen.ExampleGenerator.java</file><file>src.org.apache.pig.tools.grunt.GruntParser.java</file><file>src.org.apache.pig.tools.pigstats.PigStats.java</file><file>src.org.apache.pig.tools.pigstats.PigStatsUtil.java</file><file>src.org.apache.pig.tools.pigstats.ScriptState.java</file><file>src.org.apache.pig.tools.pigstats.SimplePigStats.java</file><file>test.org.apache.pig.parser.ParserTestingUtils.java</file><file>test.org.apache.pig.parser.ParsingFailureException.java</file><file>test.org.apache.pig.parser.TestAstValidator.java</file><file>test.org.apache.pig.parser.TestColumnAliasConversion.java</file><file>test.org.apache.pig.parser.TestDefaultDataTypeInserter.java</file><file>test.org.apache.pig.parser.TestLogicalPlanGenerator.java</file><file>test.org.apache.pig.parser.TestQueryLexer.java</file><file>test.org.apache.pig.parser.TestQueryParser.java</file><file>test.org.apache.pig.parser.TestScalarVisitor.java</file><file>test.org.apache.pig.parser.TestSchemaAliasVisitor.java</file><file>test.org.apache.pig.parser.TestUnionOnSchemaSetter.java</file><file>test.org.apache.pig.parser.TreePrinter.java</file><file>test.org.apache.pig.test.TestBestFitCast.java</file><file>test.org.apache.pig.test.TestCollectedGroup.java</file><file>test.org.apache.pig.test.TestDataBagAccess.java</file><file>test.org.apache.pig.test.TestEvalPipeline.java</file><file>test.org.apache.pig.test.TestEvalPipeline2.java</file><file>test.org.apache.pig.test.TestEvalPipelineLocal.java</file><file>test.org.apache.pig.test.TestFRJoin.java</file><file>test.org.apache.pig.test.TestForEachStar.java</file><file>test.org.apache.pig.test.TestGrunt.java</file><file>test.org.apache.pig.test.TestJoin.java</file><file>test.org.apache.pig.test.TestJoinSmoke.java</file><file>test.org.apache.pig.test.TestLogToPhyCompiler.java</file><file>test.org.apache.pig.test.TestLogicalPlanMigrationVisitor.java</file><file>test.org.apache.pig.test.TestMRCompiler.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file><file>test.org.apache.pig.test.TestMergeJoin.java</file><file>test.org.apache.pig.test.TestMultiQuery.java</file><file>test.org.apache.pig.test.TestMultiQueryBasic.java</file><file>test.org.apache.pig.test.TestMultiQueryCompiler.java</file><file>test.org.apache.pig.test.TestMultiQueryLocal.java</file><file>test.org.apache.pig.test.TestNewPlanFilterRule.java</file><file>test.org.apache.pig.test.TestNewPlanListener.java</file><file>test.org.apache.pig.test.TestNewPlanLogicalOptimizer.java</file><file>test.org.apache.pig.test.TestNewPlanOperatorPlan.java</file><file>test.org.apache.pig.test.TestNullConstant.java</file><file>test.org.apache.pig.test.TestPigRunner.java</file><file>test.org.apache.pig.test.TestPigServer.java</file><file>test.org.apache.pig.test.TestPigStats.java</file><file>test.org.apache.pig.test.TestPinOptions.java</file><file>test.org.apache.pig.test.TestProjectStarExpander.java</file><file>test.org.apache.pig.test.TestPruneColumn.java</file><file>test.org.apache.pig.test.TestScalarAliases.java</file><file>test.org.apache.pig.test.TestSchema.java</file><file>test.org.apache.pig.test.TestSkewedJoin.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file><file>test.org.apache.pig.test.TestUnionOnSchema.java</file><file>test.org.apache.pig.test.utils.TypeCheckingTestUtil.java</file></fixedFiles></bug><bug fixdate="2011-04-19 01:29:49" id="1612" opendate="2010-09-14 08:59:41"><buginformation><summary>[PIG-1612] error reporting: PigException needs to have a way to indicate that its message is appropriate for user - ASF JIRA</summary><description>The error message printed to the user by pig is the message from the exception that is the 'root cause' from the chain of getCause() of exception that has been thrown. But often the 'root cause' exception does not have enough context that would make for a better error message. It should be possible for a PigException to indicate to the code that determines the error message that its getMessage() string should be used instead of that of the 'cause' exception. The following code in LogUtils.java is used to determine the exception that is the 'root cause' - &#13;
    public static PigException getPigException(Throwable top) {&#13;
        Throwable current = top;&#13;
        Throwable pigException = top;&#13;
&#13;
        while (current != null &amp;&amp; current.getCause() != null){&#13;
            current = current.getCause();&#13;
            if((current instanceof PigException) &amp;&amp; (((PigException)current).getErrorCode() != 0)) {&#13;
                pigException = current;&#13;
            }&#13;
        }&#13;
        return (pigException instanceof PigException? (PigException)pigException : null);&#13;
        &#13;
    }</description></buginformation><fixedFiles><file>src.org.apache.pig.PigException.java</file><file>src.org.apache.pig.impl.logicalLayer.schema.Schema.java</file><file>src.org.apache.pig.impl.util.LogUtils.java</file><file>test.org.apache.pig.test.TestPigException.java</file></fixedFiles></bug><bug fixdate="2011-03-15 12:56:12" id="1566" opendate="2010-08-25 06:37:01"><buginformation><summary>[PIG-1566] Support globbing for registering jars in pig script. - ASF JIRA</summary><description>Currently user can not register pig jars with globing. For example following register script will fail. register /etc/jars/*.jar It will be great if we can support such globing for registering jars. Release notes: We allow globbing in register statement. User can use "*" to denote a globbing, eg: register key*.jar register /home/jarpath/key*.jar register jars/key*.jar The path can be absolute path or relative path start with working directory. Note globbing does not further search in classpath as non-globbing case does, eg: "register key1234.jar" works if key1234.jar in classpath, but not in working directory, however, "register key*.jar" will not locate key1234.jar in this case.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>test.org.apache.pig.test.TestPigServer.java</file></fixedFiles></bug><bug fixdate="2011-04-20 11:44:36" id="1281" opendate="2010-03-06 01:03:06"><buginformation><summary>[PIG-1281] Detect org.apache.pig.data.DataByteArray cannot be cast to org.apache.pig.data.Tuple type of errors at Compile Type during creation of logical plan - ASF JIRA</summary><description>This is more of an enhancement request, where we can detect simple errors during compile time during creation of Logical plan rather than at the backend. I created a script which contains an error which gets detected in the backend as a cast error when in fact we can detect it in the front end(group is a single element so group.$0 projection operation will not work). &#13;
inputdata = LOAD '/user/viraj/mymapdata' AS (co1, col2, col3, col4);&#13;
&#13;
projdata = FILTER inputdata BY (col1 is not null);&#13;
&#13;
groupprojdata = GROUP projdata BY col1;&#13;
&#13;
cleandata = FOREACH groupprojdata {&#13;
                     bagproj = projdata.col1;&#13;
                     dist_bags = DISTINCT bagproj;&#13;
                     GENERATE group.$0 as newcol1, COUNT(dist_bags) as newcol2;&#13;
                      };&#13;
&#13;
cleandata1 = GROUP cleandata by newcol2;&#13;
&#13;
cleandata2 = FOREACH cleandata1 { GENERATE group.$0 as finalcol1, COUNT(cleandata.newcol1) as finalcol2; };&#13;
&#13;
ordereddata = ORDER cleandata2 by finalcol2;&#13;
&#13;
store into 'finalresult' using PigStorage();</description></buginformation><fixedFiles><file>src.org.apache.pig.newplan.logical.visitor.TypeCheckingExpVisitor.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file></fixedFiles></bug><bug fixdate="2011-01-05 04:52:32" id="946" opendate="2009-09-04 11:51:37"><buginformation><summary>[PIG-946] Combiner optimizer does not optimize when limit follow group, foreach - ASF JIRA</summary><description>The following script is combinable but is not optimized: a = load '/user/pig/tests/data/singlefile/studenttab10k'; b = group a by $1; c = foreach b generate group, AVG(a.$2); d = limit c 10; dump d;</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.CombinerOptimizer.java</file><file>test.org.apache.pig.test.TestCombiner.java</file></fixedFiles></bug><bug fixdate="2011-02-08 06:22:09" id="847" opendate="2009-06-12 11:33:10"><buginformation><summary>[PIG-847] Setting twoLevelAccessRequired field in a bag schema should not be required to access fields in the tuples of the bag - ASF JIRA</summary><description>Currently Pig interprets the result type of a relation as a bag. However the schema of the relation directly contains the schema describing the fields in the tuples for the relation. However when a udf wants to return a bag or if there is a bag in input data or if the user creates a bag constant, the schema of the bag has one field schema which is that of the tuple. The Tuple's schema has the types of the fields. To be able to access the fields from the bag directly in such a case by using something like &lt;bagname&gt;.&lt;fieldname&gt; or &lt;bag&gt;.&lt;fieldposition&gt;, the schema of the bag should have the twoLevelAccess set to true so that pig's type system can get traverse the tuple schema and get to the field in question. This is confusing - we should try and see if we can avoid needing this extra flag. A possible solution is to treat bags the same way - whether they represent relations or real bags. Another way is to introduce a special "relation" datatype for the result type of a relation and bag type would be used only for true bags. In this case, we would always need bag schema to have a tuple schema which would describe the fields.</description></buginformation><fixedFiles><file>src.org.apache.pig.ResourceSchema.java</file><file>src.org.apache.pig.builtin.TOKENIZE.java</file><file>src.org.apache.pig.data.DataType.java</file><file>src.org.apache.pig.impl.logicalLayer.LOForEach.java</file><file>src.org.apache.pig.impl.logicalLayer.LOProject.java</file><file>src.org.apache.pig.impl.logicalLayer.schema.Schema.java</file><file>src.org.apache.pig.newplan.logical.Util.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalSchema.java</file><file>src.org.apache.pig.newplan.logical.rules.DuplicateForEachColumnRewrite.java</file><file>src.org.apache.pig.newplan.logical.rules.InputOutputFileValidator.java</file><file>test.org.apache.pig.test.TestLogicalPlanMigrationVisitor.java</file><file>test.org.apache.pig.test.TestSchema.java</file></fixedFiles></bug><bug fixdate="2010-12-19 03:59:30" id="750" opendate="2009-04-03 12:59:55"><buginformation><summary>[PIG-750] Use combiner when algebraic UDFs are used in expressions - ASF JIRA</summary><description>Currently Pig uses combiner when all a,b, c,... are algebraic (e.g. SUM, AVG etc.) in foreach: foreach X generate a,b,c,... It's a performance improvement if it uses combiner when a mix of algebraic and non-algebraic functions are used as well.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.CombinerOptimizer.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POCombinerPackage.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage.java</file><file>test.org.apache.pig.test.TestCombiner.java</file><file>test.org.apache.pig.test.TestMultiQueryCompiler.java</file></fixedFiles></bug><bug fixdate="2011-04-14 05:25:12" id="1959" opendate="2011-04-02 06:59:04"><buginformation><summary>[PIG-1959] Penny: a framework for workflow instrumentation - ASF JIRA</summary><description>Penny is a framework for instrumenting Pig workflows. It rewrites scripts to insert monitoring points, aka agents, and provides a communication framework for triggering and collecting events from these agents.</description></buginformation><fixedFiles><file>contrib.penny.java.src.main.java.org.apache.pig.penny.ClassWithArgs.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.Communicator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.Coordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.Location.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.LogicalLocation.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.MonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.NoSuchLocationException.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.ParsedPigScript.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.PennyServer.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.PhysicalLocation.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTInjectTaintMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTMatchTaintMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.BTPropagateTaintMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.bt.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ci.CICoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ci.CIMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ci.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.dh.DHCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.dh.DHMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.dh.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ds.DSCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ds.DSMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ds.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ft.FTCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ft.FTMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ft.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GLCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GLMonitorAgent1.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GLMonitorAgent2.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.GoldenLogic.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.gl.goldenLogicClasses.FlattenLinksGL.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.la.LACoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.la.LAMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.la.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.lp.LPCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.lp.LPMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.lp.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.nop.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.nop.NOPCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.nop.NOPMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.op.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.op.OPCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.op.OPMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ri.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ri.RICoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ri.RIMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ti.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ti.TICoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.ti.TIMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.tr.Main.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.tr.TRCoordinator.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.apps.tr.TRMonitorAgent.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.AsyncMessageReceiptCallback.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.Message.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.MessageReceiptCallback.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.comm.SyncCallResult.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.CoordinatorHarness.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.MessagingClient.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.MessagingServer.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.harnesses.MonitorAgentHarness.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.pig.MonitorAgentUDF.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.pig.MonitorAgentUDFArgs.java</file><file>contrib.penny.java.src.main.java.org.apache.pig.penny.impl.pig.PigLauncher.java</file><file>contrib.penny.java.src.test.java.org.apache.pig.penny.test.ComTest.java</file><file>contrib.penny.java.src.test.java.org.apache.pig.penny.test.PennyAgentTest.java</file><file>src.org.apache.pig.tools.ToolsPigServer.java</file></fixedFiles></bug><bug fixdate="2011-03-22 09:27:22" id="1924" opendate="2011-03-20 11:01:57"><buginformation><summary>[PIG-1924] CSV Loader/Store that handles newlines in fields, and other Excel CSV features. - ASF JIRA</summary><description>CSVExcelStorage() combines load and store of CSV encoded data. Handles newlines within fields, escaped double quotes, and double quoting of fields with embedded field delimiters. Newline handling is optional, and controlled by a parameter. The module also offers an option to output with Windows style newlines (CRLF, instead of the Unix LF). All CSV related syntax decisions were made to match Excel 2007. The module comes with a test file, and javadoc produces proper documentation files.</description></buginformation><fixedFiles><file>contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.storage.TestCSVExcelStorage.java</file></fixedFiles></bug><bug fixdate="2011-04-13 01:10:20" id="1881" opendate="2011-03-03 05:34:33"><buginformation><summary>[PIG-1881] Need a special interface for Penny (Inspector Gadget) - ASF JIRA</summary><description>The proposed Penny tool needs access to Pig's new logical plan in order to inject code into the the dataflow. Once it has modified the plan it needs to then be able to hand back that modified plan and have Pig execute it. As we don't want to open this functionality up to general users, the proposal is to do this by subclasses PigServer with a new class that is marked as LimitedPrivate for Penny only. This class will provide calls to parse a Pig Latin script and return a logical plan, and one to take a logical plan and execute it.</description></buginformation><fixedFiles><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.tools.ToolsPigServer.java</file><file>src.org.apache.pig.tools.grunt.GruntParser.java</file><file>test.org.apache.pig.test.TestToolsPigServer.java</file></fixedFiles></bug><bug fixdate="2011-03-09 10:52:10" id="1876" opendate="2011-03-01 11:54:23"><buginformation><summary>[PIG-1876] Typed map for Pig - ASF JIRA</summary><description>Currently Pig map type is untyped, which means map value is always of bytearray(ie. unknown) type. In PIG-1277, we allow unknown type to be a shuffle key, which somewhat relieve the problem. However, typed map is still beneficial in that: 1. User can make semantic use of the map value type. Currently, user need to explicitly cast map value, which is ugly 2. Though PIG-1277 allow unknown type be a shuffle key, the performance suffers. We don't have a raw comparator for the unknown type, instead, we need to instantiate the value object and invoke its comparator Here is proposed syntax for typed map: map[type] Typed map can be used in place of untyped map could occur. For example: a = load '1.txt' as(map[int]); b = foreach a generate (map[(i:int)])a0; - - Map value is tuple b = stream a through `cat` as (m:map[ {(i:int,j:chararray)} ]); - - Map value is bag MapLookup a typed map will result datatype of map value. a = load '1.txt' as(map[int]); b = foreach a generate $0#'key'; Schema for b: b: {int} The behavior of untyped map will remain the same.</description></buginformation><fixedFiles><file>src.org.apache.pig.LoadCaster.java</file><file>src.org.apache.pig.ResourceSchema.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.java</file><file>src.org.apache.pig.backend.hadoop.hbase.HBaseBinaryConverter.java</file><file>src.org.apache.pig.builtin.BinStorage.java</file><file>src.org.apache.pig.builtin.TextLoader.java</file><file>src.org.apache.pig.builtin.Utf8StorageConverter.java</file><file>src.org.apache.pig.data.DataType.java</file><file>src.org.apache.pig.impl.io.ReadToEndLoader.java</file><file>src.org.apache.pig.impl.logicalLayer.schema.Schema.java</file><file>src.org.apache.pig.newplan.logical.LogicalExpPlanMigrationVistor.java</file><file>src.org.apache.pig.newplan.logical.expression.MapLookupExpression.java</file><file>src.org.apache.pig.newplan.logical.relational.LogicalSchema.java</file><file>src.org.apache.pig.newplan.logical.visitor.ColumnAliasConversionVisitor.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file><file>test.org.apache.pig.test.TestPOCast.java</file><file>test.org.apache.pig.test.TestTypedMap.java</file></fixedFiles></bug><bug fixdate="2011-02-23 11:02:28" id="1794" opendate="2011-01-09 10:51:53"><buginformation><summary>[PIG-1794] Javascript support for Pig embedding and UDFs in scripting languages - ASF JIRA</summary><description>The attached patch proposes a javascript implementation for Pig embedding and UDFs in scripting languages. It is similar to the Jython implementation and uses Rhino provided in the JDK. some differences: output schema is provided by: &lt;functionName&gt;.outSchema="&lt;schema&gt;" as javascript does not have annotations or decorators but functions are first class objects tuples are converted to objects using the input schema (the other way around using the output schema) The attached patch is not final yet. In particular it lacks unit tests. See test/org/apache/pig/test/data/tc.js for the "transitive closure" example See the following JIRAs for more context: https://issues.apache.org/jira/browse/PIG-928 https://issues.apache.org/jira/browse/PIG-1479</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.scripting.Pig.java</file><file>src.org.apache.pig.scripting.ScriptEngine.java</file><file>src.org.apache.pig.scripting.ScriptPigContext.java</file><file>src.org.apache.pig.scripting.js.JSPig.java</file><file>src.org.apache.pig.scripting.js.JsFunction.java</file><file>src.org.apache.pig.scripting.js.JsScriptEngine.java</file><file>src.org.apache.pig.scripting.js.Pig.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file><file>test.org.apache.pig.test.TestScriptLanguageJavaScript.java</file><file>test.org.apache.pig.test.Util.java</file></fixedFiles></bug><bug fixdate="2011-02-15 01:09:47" id="1793" opendate="2011-01-08 12:10:15"><buginformation><summary>[PIG-1793] Add macro expansion to Pig Latin - ASF JIRA</summary><description>As production Pig scripts grow longer and longer, Pig Latin has a need to integrate standard programming techniques of separation and code sharing offered by functions and modules. A proposal of adding macro expansion to Pig Latin is posted here: http://wiki.apache.org/pig/TuringCompletePig Below is a brief summary of the proposed syntax (and examples): Macro Definition The existing DEFINE keyword will be expanded to allow definitions of Pig macros. Syntax &#13;
define &lt;name&gt; (&lt;params&gt;) returns &lt;aliases&gt; {&#13;
    &lt;Pig Latin fragment&gt;&#13;
};&#13;
 Example &#13;
define my_macro(A, sortkey) returns C {&#13;
    B = filter $A by my_filter(*);&#13;
    $C = order B by $sortkey;&#13;
}&#13;
 Macro Expansion Syntax &#13;
&lt;aliases&gt; = &lt;macro name&gt; (&lt;params&gt;);&#13;
 Example: Use above macro in a Pig script: &#13;
X = load 'foo' as (user, address, phone);&#13;
Y = my_macro(X, user);&#13;
store Y into 'bar';&#13;
 This script is expanded into the following Pig Latin statements: &#13;
X = load 'foo' as (user, address, phone);&#13;
macro_my_macro_B_1 = filter X by my_filter(*);&#13;
Y = order macro_my_macro_B_1 by user;&#13;
store Y into 'bar';&#13;
 Notes 1. Any alias in the macro which isn't visible from outside will be prefixed with macro name and suffixed with instance id to avoid namespace collision. 2. Macro expansion is not a complete replacement for function calls. Recursive expansions are not supported. Macro Import The new IMPORT keyword can be used to add macros defined in another Pig Latin file. Syntax &#13;
import &lt;Pig Latin file name&gt;;&#13;
 Example &#13;
import my_macro.pig;&#13;
 Note: All macro names are in the global namespace.</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.parser.ParserUtil.java</file><file>src.org.apache.pig.parser.PigMacro.java</file><file>src.org.apache.pig.scripting.Pig.java</file><file>test.org.apache.pig.test.TestMacroExpansion.java</file></fixedFiles></bug><bug fixdate="2011-04-17 08:01:05" id="1782" opendate="2010-12-30 04:32:26"><buginformation><summary>[PIG-1782] Add ability to load data by column family in HBaseStorage - ASF JIRA</summary><description>It would be nice to load all columns in the column family by using short hand syntax like: CpuMetrics = load 'hbase://SystemMetrics' USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('cpu:','-loadKey');&#13;
 Assuming there are columns cpu: sys.0, cpu:sys.1, cpu:user.0, cpu:user.1, in cpu column family. CpuMetrics would contain something like: (rowKey, cpu:sys.0, cpu:sys.1, cpu:user.0, cpu:user.1)</description></buginformation><fixedFiles><file>a.src.org.apache.pig.backend.hadoop.hbase.HBaseStorage.java</file><file>a.test.org.apache.pig.test.TestHBaseStorage.java</file><file>src.org.apache.pig.backend.hadoop.hbase.HBaseStorage.java</file><file>src.org.apache.pig.backend.hadoop.hbase.HBaseTableInputFormat.java</file><file>test.org.apache.pig.test.TestHBaseStorage.java</file></fixedFiles></bug><bug fixdate="2010-12-10 01:40:24" id="1758" opendate="2010-12-07 11:43:13"><buginformation><summary>[PIG-1758] Deep cast of complex type - ASF JIRA</summary><description>Pig does not handle deep cast from bag -&gt; bag, tuple -&gt; tuple. Eg, the following script does not produce desired result: &#13;
a = load '1.txt' as (a0:bag{t:tuple(i0:double)});&#13;
b = foreach a generate (bag{tuple(int)})a0;&#13;
dump b;&#13;
 The result tuple still contain int inside tuple of bag. PIG-613 fix the case we cast bytearray &gt; bag/tuple, we take complex type including inner types, but bag&gt;bag, tuple-&gt;tuple is still not effective.</description></buginformation><fixedFiles><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POCast.java</file><file>test.org.apache.pig.test.TestPOCast.java</file></fixedFiles></bug><bug fixdate="2010-12-06 09:45:10" id="1752" opendate="2010-12-03 12:49:40"><buginformation><summary>[PIG-1752] UDFs should be able to indicate files to load in the distributed cache - ASF JIRA</summary><description>Currently there is no way for a UDF to load a file into the distributed cache.</description></buginformation><fixedFiles><file>src.org.apache.pig.EvalFunc.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POUserFunc.java</file><file>src.org.apache.pig.newplan.logical.expression.ExpToPhyTranslationVisitor.java</file></fixedFiles></bug><bug fixdate="2010-11-16 06:24:52" id="1722" opendate="2010-11-12 04:29:48"><buginformation><summary>[PIG-1722] PiggyBank AllLoader - Load multiple file formats in one load statement - ASF JIRA</summary><description>This gives the ability to point one loader at a directory and have multiple formats loaded and used in the same query ----- Overview ----- Lets say we have a directory with files: /logs/myfile.lzo /logs/myfile.rc /logs/myfile.bz2 /logs/myfile.gz To load these currently requires multiple loaders, load statements in pig and then have the query perform a union on these. With this Loader the query becomes: a = LOAD '/logs/' USING org.apache.pig.piggybank.storage.AllLoader(); The AllLoader will use the mapping property in the $PIG_HOME/conf/pig.properties file.extension.loaders that can be setup as: file.extension.loaders=gz:org.apache.pig.builtin.PigStorage(),bz2:org.apache.pig.builtin.PigStorage(),lzo:com.twitter.elephantbird.pig.load.LzoTextLoader(), rc:org.apache.pig.piggybank.storage.HiveColumnarLoader() The formats of this property is: -&gt; [file extension]:[loader func spec] -&gt; [file-extension]:[optional path tag]:[loader func spec] -&gt; [file-extension]:[optional path tag]:[sequence file key value writer class name]:[loader func spec] ----- File path tagging: ----- Loaders can also be chosen based on folder names in the file path: e.g. file.extension.loaders:gz:type1:Type1Loader(), gz:type2:Type2Loader() So that if you have /logs/type1/mylog and /logs/type2/mylog doing : a = LOAD '/logs/' USING org.apache.pig.piggybank.storage.AllLoader(); will use Type1Loader for mylog in /logs/type1 and Type2Loader for mylog in /logs/type2 ----- File content guessing: ----- If the files do not have extensions the AllLoader will try to guess the type of file by looking at the first three bytes mapping the following bytes to each extension: [ -119, 76, 90 ] = lzo [ 31, -117, 8 ] = gz [ 66, 90, 104 ] = bz2 [ 83, 69, 81 ] = seq ----- Loader selection based on sequence file writer class ----- Loaders can be configured to be selected based on the getKeyClassName of the Sequence File. e.g. file.extension.loaders:seq::org.apache.hadoop.hive.ql.io.RCFile:HiveColumnarLoader will use the HiveColumnarLoader loader for all sequence files that have been written with org.apache.hadoop.hive.ql.io.RCFile as the KeyClassName. All $ extensions are removed from the getKeyClassName's return value. ----- Path Partition Handling ----- Hive style partitioning is supported in the Loader itself so that if you have /logs/type=1 /logs/type=2 /logs/type=3 The partition columns will be recougnised as "type" and filtering can be done like type&lt;=2 etc. For this current implementation filtering expressions should be passed into the AllLoader's constructor e.g. a = LOAD '/logs/' USING org.apache.pig.piggybank.storage.AllLoader('type&lt;=2'); will load only files that are in /logs/type=1 and /logs/type=2</description></buginformation><fixedFiles><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.AllLoader.java</file><file>contrib.piggybank.java.src.main.java.org.apache.pig.piggybank.storage.allloader.LoadFuncHelper.java</file><file>contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.storage.TestAllLoader.java</file><file>contrib.piggybank.java.src.test.java.org.apache.pig.piggybank.test.storage.TestLoadFuncHelper.java</file></fixedFiles></bug><bug fixdate="2011-03-28 02:02:17" id="1693" opendate="2010-10-22 06:55:22"><buginformation><summary>[PIG-1693] support project-range expression. (was: There needs to be a way in foreach to indicate "and all the rest of the fields" ) - ASF JIRA</summary><description>A common use case we see in Pig is people have many columns in their data and they only want to operate on a few of them. Consider for example if before storing data with ten columns, the user wants to perform a cast on one column: &#13;
...&#13;
Z = foreach Y generate (int)firstcol, secondcol, thridcol, forthcol, fifthcol, sixthcol, seventhcol, eigthcol, ninethcol, tenthcol;&#13;
store Z into 'output';&#13;
 Obviously this only gets worse as the user has more columns. Ideally the above could be transformed to something like: &#13;
...&#13;
Z = foreach Y generate (int)firstcol, "and all the rest";&#13;
store Z into 'output'</description></buginformation><fixedFiles><file>src.org.apache.pig.PigWarning.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.ColumnInfo.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.CombinerOptimizer.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizer.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.POProject.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.expressionOperators.PORelationToExprProject.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POForEach.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POLocalRearrange.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POPackage.java</file><file>src.org.apache.pig.backend.hadoop.executionengine.physicalLayer.relationalOperators.POSort.java</file><file>src.org.apache.pig.newplan.logical.expression.ExpToPhyTranslationVisitor.java</file><file>src.org.apache.pig.newplan.logical.expression.ProjectExpression.java</file><file>src.org.apache.pig.newplan.logical.relational.LOInnerLoad.java</file><file>src.org.apache.pig.newplan.logical.relational.LOSort.java</file><file>src.org.apache.pig.newplan.logical.relational.LogToPhyTranslationVisitor.java</file><file>src.org.apache.pig.newplan.logical.rules.ColumnPruneHelper.java</file><file>src.org.apache.pig.newplan.logical.rules.FilterAboveForeach.java</file><file>src.org.apache.pig.newplan.logical.rules.MergeForEach.java</file><file>src.org.apache.pig.newplan.logical.visitor.ColumnAliasConversionVisitor.java</file><file>src.org.apache.pig.newplan.logical.visitor.ProjectStarExpander.java</file><file>src.org.apache.pig.parser.LogicalPlanBuilder.java</file><file>src.org.apache.pig.parser.ParserException.java</file><file>test.org.apache.pig.test.TestProjectRange.java</file><file>test.org.apache.pig.test.TestTypeCheckingValidatorNewLP.java</file><file>test.org.apache.pig.test.Util.java</file></fixedFiles></bug><bug fixdate="2011-01-07 10:18:01" id="1479" opendate="2010-07-01 09:30:01"><buginformation><summary>[PIG-1479] Embed Pig in scripting languages - ASF JIRA</summary><description>It should be possible to embed Pig calls in a scripting language and let functions defined in the same script available as UDFs. This is a spin off of https://issues.apache.org/jira/browse/PIG-928 which lets users define UDFs in scripting languages.</description></buginformation><fixedFiles><file>src.org.apache.pig.Main.java</file><file>src.org.apache.pig.PigServer.java</file><file>src.org.apache.pig.scripting.BoundPipeline.java</file><file>src.org.apache.pig.scripting.BoundScript.java</file><file>src.org.apache.pig.scripting.MultiBoundPipeline.java</file><file>src.org.apache.pig.scripting.Pig.java</file><file>src.org.apache.pig.scripting.PigPipeline.java</file><file>src.org.apache.pig.scripting.ScriptEngine.java</file><file>src.org.apache.pig.scripting.ScriptPigContext.java</file><file>src.org.apache.pig.scripting.ScriptPigServer.java</file><file>src.org.apache.pig.scripting.SyncProgressNotificationAdaptor.java</file><file>src.org.apache.pig.scripting.jython.JythonFunction.java</file><file>src.org.apache.pig.scripting.jython.JythonScriptEngine.java</file><file>src.org.apache.pig.scripting.jython.JythonUtils.java</file><file>src.org.apache.pig.tools.pigstats.EmbeddedPigStats.java</file><file>src.org.apache.pig.tools.pigstats.JobStats.java</file><file>src.org.apache.pig.tools.pigstats.OutputStats.java</file><file>src.org.apache.pig.tools.pigstats.PigProgressNotificationListener.java</file><file>src.org.apache.pig.tools.pigstats.PigStats.java</file><file>src.org.apache.pig.tools.pigstats.PigStatsUtil.java</file><file>src.org.apache.pig.tools.pigstats.ScriptState.java</file><file>src.org.apache.pig.tools.pigstats.SimplePigStats.java</file><file>test.org.apache.pig.test.TestPigRunner.java</file><file>test.org.apache.pig.test.TestScriptLanguage.java</file></fixedFiles></bug></bugrepository>