<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository><bug fixdate="2011-11-02 09:59:00" id="1271" opendate="2011-10-28 11:33:08"><buginformation><summary>[ZOOKEEPER-1271] testEarlyLeaderAbandonment failing on solaris - clients not retrying connection - ASF JIRA</summary><description>See: https://builds.apache.org/view/S-Z/view/ZooKeeper/job/ZooKeeper_branch34_solaris/1/testReport/junit/org.apache.zookeeper.server.quorum/QuorumPeerMainTest/testEarlyLeaderAbandonment/ Notice that the clients attempt to connect before the servers have bound, then 30 seconds later, after seemingly no further client activity we see: 2011-10-28 21:40:56,828 [myid:] - INFO [main-SendThread(localhost:11227):ClientCnxn$SendThread@1057] - Client session timed out, have not heard from server in 30032ms for sessionid 0x0, closing socket connection and attempting reconnect I believe this is different from ZOOKEEPER-1270 because in the 1270 case it seems like the clients are attempting to connect but the servers are not accepting (notice the stat commands are being dropped due to no server running)</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.ClientCnxn.java</file><file>src.java.main.org.apache.zookeeper.ClientCnxnSocketNIO.java</file></fixedFiles></bug><bug fixdate="2011-11-05 11:46:06" id="1270" opendate="2011-10-28 11:25:36"><buginformation><summary>[ZOOKEEPER-1270] testEarlyLeaderAbandonment failing intermittently, quorum formed, no serving. - ASF JIRA</summary><description>Looks pretty serious - quorum is formed but no clients can attach. Will attach logs momentarily. This test was introduced in the following commit (all three jira commit at once): ZOOKEEPER-335. zookeeper servers should commit the new leader txn to their logs. ZOOKEEPER-1081. modify leader/follower code to correctly deal with new leader ZOOKEEPER-1082. modify leader election to correctly take into account current</description></buginformation><fixedFiles><file>src.java.test.org.apache.zookeeper.server.quorum.QuorumPeerMainTest.java</file><file>src.java.test.org.apache.zookeeper.test.ClientBase.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.Leader.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.LearnerHandler.java</file><file>src.java.test.org.apache.zookeeper.server.quorum.Zab1_0Test.java</file></fixedFiles></bug><bug fixdate="2011-11-01 07:15:50" id="1268" opendate="2011-10-28 07:01:05"><buginformation><summary>[ZOOKEEPER-1268] problems with read only mode, intermittent test failures and ERRORs in the log - ASF JIRA</summary><description>I'm having a lot problems testing the 3.4.0 release candidate (0). I'm seeing frequent failures in RO unit tests, also the solaris tests are broken on jenkins, some of which is due to RO mode: https://builds.apache.org/view/S-Z/view/ZooKeeper/job/ZooKeeper_trunk_solaris/30/#showFailuresLink I'm also seeing ERROR level messages in the logs during test runs that are a result of attempting to start RO mode. Given this is a new feature, one that could be very disruptive, I think we need to control whether the feature is enabled or not through a config option (system prop is fine), disabled by default. I'll look at the RO mode tests to see if I can find the cause of the failures on solaris, but I may also turn off these tests for the time being. (I need to look at this further). I'm marking this as a blocker for 3.4.0, Mahadev LMK if you feel similarly or whether I should be shooting for 3.4.1 with this. (or perhaps I'm just way off in general).</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.QuorumPeer.java</file><file>src.java.test.org.apache.zookeeper.test.ReadOnlyModeTest.java</file></fixedFiles></bug><bug fixdate="2011-11-05 08:58:22" id="1264" opendate="2011-10-28 05:23:28"><buginformation><summary>[ZOOKEEPER-1264] FollowerResyncConcurrencyTest failing intermittently - ASF JIRA</summary><description>The FollowerResyncConcurrencyTest test is failing intermittently. saw the following on 3.4: junit.framework.AssertionFailedError: Should have same number of&#13;
ephemerals in both followers expected:&lt;11741&gt; but was:&lt;14001&gt;&#13;
       at org.apache.zookeeper.test.FollowerResyncConcurrencyTest.verifyState(FollowerResyncConcurrencyTest.java:400)&#13;
       at org.apache.zookeeper.test.FollowerResyncConcurrencyTest.testResyncBySnapThenDiffAfterFollowerCrashes(FollowerResyncConcurrencyTest.java:196)&#13;
       at org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:52)</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.Leader.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.Learner.java</file><file>src.java.test.org.apache.zookeeper.test.QuorumTest.java</file><file>src.java.test.org.apache.zookeeper.test.FollowerResyncConcurrencyTest.java</file><file>src.java.test.org.apache.zookeeper.server.quorum.Zab1_0Test.java</file></fixedFiles></bug><bug fixdate="2011-11-14 07:34:12" id="1208" opendate="2011-09-28 05:35:47"><buginformation><summary>[ZOOKEEPER-1208] Ephemeral node not removed after the client session is long gone - ASF JIRA</summary><description>Copying from email thread. We found our ZK server in a state where an ephemeral node still exists after a client session is long gone. I used the cons command on each ZK host to list all connections and couldn't find the ephemeralOwner id. We are using ZK 3.3.3. Has anyone seen this problem? I got the following information from the logs. The node that still exists is /kafka-tracking/consumers/UserPerformanceEvent-&lt;host&gt;/owners/UserPerformanceEvent/529-7 I saw that the ephemeral owner is 86167322861045079 which is session id 0x13220b93e610550. After searching in the transaction log of one of the ZK servers found that session expired 9/22/11 12:17:57 PM PDT session 0x13220b93e610550 cxid 0x74 zxid 0x601bd36f7 closeSession null On digging further into the logs I found that there were multiple sessions created in quick succession and every session tried to create the same node. But i verified that the sessions were closed and opened in order 9/22/11 12:17:56 PM PDT session 0x13220b93e610550 cxid 0x0 zxid 0x601bd36b5 createSession 6000 9/22/11 12:17:57 PM PDT session 0x13220b93e610550 cxid 0x74 zxid 0x601bd36f7 closeSession null 9/22/11 12:17:58 PM PDT session 0x13220b93e610551 cxid 0x0 zxid 0x601bd36f8 createSession 6000 9/22/11 12:17:59 PM PDT session 0x13220b93e610551 cxid 0x74 zxid 0x601bd373a closeSession null 9/22/11 12:18:00 PM PDT session 0x13220b93e610552 cxid 0x0 zxid 0x601bd373e createSession 6000 9/22/11 12:18:01 PM PDT session 0x13220b93e610552 cxid 0x6c zxid 0x601bd37a0 closeSession null 9/22/11 12:18:02 PM PDT session 0x13220b93e610553 cxid 0x0 zxid 0x601bd37e9 createSession 6000 9/22/11 12:18:03 PM PDT session 0x13220b93e610553 cxid 0x74 zxid 0x601bd382b closeSession null 9/22/11 12:18:04 PM PDT session 0x13220b93e610554 cxid 0x0 zxid 0x601bd383c createSession 6000 9/22/11 12:18:05 PM PDT session 0x13220b93e610554 cxid 0x6a zxid 0x601bd388f closeSession null 9/22/11 12:18:06 PM PDT session 0x13220b93e610555 cxid 0x0 zxid 0x601bd3895 createSession 6000 9/22/11 12:18:07 PM PDT session 0x13220b93e610555 cxid 0x6a zxid 0x601bd38cd closeSession null 9/22/11 12:18:10 PM PDT session 0x13220b93e610556 cxid 0x0 zxid 0x601bd38d1 createSession 6000 9/22/11 12:18:11 PM PDT session 0x13220b93e610557 cxid 0x0 zxid 0x601bd38f2 createSession 6000 9/22/11 12:18:11 PM PDT session 0x13220b93e610557 cxid 0x51 zxid 0x601bd396a closeSession null Here is the log output for the sessions that tried creating the same node 9/22/11 12:17:54 PM PDT session 0x13220b93e61054f cxid 0x42 zxid 0x601bd366b create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:17:56 PM PDT session 0x13220b93e610550 cxid 0x42 zxid 0x601bd36ce create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:17:58 PM PDT session 0x13220b93e610551 cxid 0x42 zxid 0x601bd3711 create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:18:00 PM PDT session 0x13220b93e610552 cxid 0x42 zxid 0x601bd3777 create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:18:02 PM PDT session 0x13220b93e610553 cxid 0x42 zxid 0x601bd3802 create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:18:05 PM PDT session 0x13220b93e610554 cxid 0x44 zxid 0x601bd385d create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:18:07 PM PDT session 0x13220b93e610555 cxid 0x44 zxid 0x601bd38b0 create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 9/22/11 12:18:11 PM PDT session 0x13220b93e610557 cxid 0x52 zxid 0x601bd396b create '/kafka-tracking/consumers/UserPerformanceEvent-&lt;hostname&gt;/owners/UserPerformanceEvent/529-7 Let me know if you need additional information.</description></buginformation><fixedFiles><file>src.java.test.org.apache.zookeeper.server.PrepRequestProcessorTest.java</file><file>src.java.main.org.apache.zookeeper.server.SessionTracker.java</file><file>src.java.main.org.apache.zookeeper.server.SessionTrackerImpl.java</file><file>src.java.main.org.apache.zookeeper.server.FinalRequestProcessor.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.LearnerSessionTracker.java</file><file>src.java.main.org.apache.zookeeper.server.PrepRequestProcessor.java</file><file>src.java.main.org.apache.zookeeper.server.ZooKeeperServer.java</file></fixedFiles></bug><bug fixdate="2011-09-29 10:36:43" id="1206" opendate="2011-09-27 05:26:16"><buginformation><summary>[ZOOKEEPER-1206] Sequential node creation does not use always use digits in node name given certain Locales. - ASF JIRA</summary><description>While I always expect to be able to parse a sequential node by looking for digits, under some locals you end up with non digits - for example: n_०००००००००० It looks like the problem is around line 236 in PrepRequestProcessor: &#13;
                if (createMode.isSequential()) {&#13;
                    path = path + String.format("%010d", parentCVersion);&#13;
                }&#13;
 Instead we should pass Locale.ENGLISH to the format call. &#13;
                if (createMode.isSequential()) {&#13;
                    path = path + String.format(Locale.ENGLISH, "%010d", parentCVersion);&#13;
                }&#13;
 Lucene/Solr tests with random Locales, and some of my tests that try and inspect the node name and order things expect to find digits - currently my leader election recipe randomly fails when the wrong locale pops up.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.PrepRequestProcessor.java</file></fixedFiles></bug><bug fixdate="2011-09-29 08:42:51" id="1195" opendate="2011-09-20 04:15:41"><buginformation><summary>[ZOOKEEPER-1195] SASL authorizedID being incorrectly set: should use getHostName() rather than getServiceName() - ASF JIRA</summary><description>Tom Klonikowski writes: Hello developers, the SaslServerCallbackHandler in trunk changes the principal name service/host@REALM to service/service@REALM (i guess unintentionally). lines 131-133: if (!removeHost() &amp;&amp; (kerberosName.getHostName() != null)) { userName += "/" + kerberosName.getServiceName(); } Server Log: SaslServerCallbackHandler@115] - Successfully authenticated client: authenticationID=fetcher/ubook@QUINZOO; authorizationID=fetcher/ubook@QUINZOO. SaslServerCallbackHandler@137] - Setting authorizedID: fetcher/fetcher@QUINZOO</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.auth.SaslServerCallbackHandler.java</file></fixedFiles></bug><bug fixdate="2011-11-05 06:38:24" id="1194" opendate="2011-09-20 01:10:08"><buginformation><summary>[ZOOKEEPER-1194] Two possible race conditions during leader establishment - ASF JIRA</summary><description>Leader.getEpochToPropose() and Leader.waitForNewEpoch() act as barriers - they make sure that a leader/follower can return from calling the method only once connectingFollowers (or electingFollowers) contain a quorum. But these methods don't make sure that the leader itself is in connectingFollowers/electingFollowers. So the leader didn't necessarily reach the barrier when followers pass it. This can cause the following problems: 1. If the leader is not in connectingFollowers when a LearnerHandler returns from getEpochToPropose(), then the epoch sent by the leader to the follower might be smaller than the leader's own last accepted epoch. 2. If the leader is not in electingFollowers when LearnerHandler returns from waitForNewEpoch() then the leader will send a NEWLEADER message to followers, and the followers will respond, but it is possible that the NEWLEADER message is not in outstandingProposals when these NEWLEADER acks arrive, which will cause the NEWLEADER acks to be dropped. To fix this I propose to explicitly check that the leader is in connectingFollowers/electingFollowers before anyone can pass these barriers.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.Leader.java</file><file>src.java.test.org.apache.zookeeper.server.quorum.Zab1_0Test.java</file></fixedFiles></bug><bug fixdate="2011-11-05 06:15:12" id="1192" opendate="2011-09-19 03:00:24"><buginformation><summary>[ZOOKEEPER-1192] Leader.waitForEpochAck() checks waitingForNewEpoch instead of checking electionFinished - ASF JIRA</summary><description>A follower/leader should block in Leader.waitForEpochAck() until either electingFollowers contains a quorum and electionFinished=true or until a timeout occurs. A timeout means that a quorum of followers didn't ack the epoch on time, which is an error. But the check in Leader.waitForEpochAck() is "if (waitingForNewEpoch) throw..." and this will never be triggered, even if the wait statement just timed out, because Leader.getEpochToPropose() completes and sets waitingForNewEpoch to false before Leader.waitForEpochAck() is invoked. Instead of "if (waitingForNewEpoch) throw" the condition in Leader.waitForEpochAck() should be "if (!electionFinished) throw". The guarded block introduced in ZK-1191 should be checking !electionFinished.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.Leader.java</file><file>src.java.test.org.apache.zookeeper.server.quorum.Zab1_0Test.java</file></fixedFiles></bug><bug fixdate="2011-09-27 02:11:20" id="1189" opendate="2011-09-16 03:29:05"><buginformation><summary>[ZOOKEEPER-1189] For an invalid snapshot file(less than 10bytes size) RandomAccessFile stream is leaking. - ASF JIRA</summary><description>When loading the snapshot, ZooKeeper will consider only the 'snapshots with atleast 10 bytes size'. Otherwsie it will ignore and just return without closing the RandomAccessFile. Util.isValidSnapshot() having the following logic. &#13;
       // Check for a valid snapshot&#13;
        RandomAccessFile raf = new RandomAccessFile(f, "r");&#13;
        // including the header and the last / bytes&#13;
        // the snapshot should be atleast 10 bytes&#13;
        if (raf.length() &lt; 10) {&#13;
            return false;&#13;
        }&#13;
 Since the snapshot file validation logic is outside try block, it won't go to the finally block and will be leaked. Suggestion: Move the validation logic to the try/catch block.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.persistence.Util.java</file><file>src.java.test.org.apache.zookeeper.server.ZooKeeperServerTest.java</file></fixedFiles></bug><bug fixdate="2011-09-27 03:09:47" id="1185" opendate="2011-09-15 02:11:09"><buginformation><summary>[ZOOKEEPER-1185] Send AuthFailed event to client if SASL authentication fails - ASF JIRA</summary><description>There are 3 places where ClientCnxn should queue a AuthFailed event if client fails to authenticate. Without sending this event, clients may be stuck watching for a SaslAuthenticated event that will never come (since the client failed to authenticate).</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.ClientCnxn.java</file><file>src.java.main.org.apache.zookeeper.client.ZooKeeperSaslClient.java</file><file>src.java.test.org.apache.zookeeper.test.SaslAuthTest.java</file><file>src.java.test.org.apache.zookeeper.test.SaslAuthFailTest.java</file></fixedFiles></bug><bug fixdate="2011-10-24 07:47:23" id="1181" opendate="2011-09-14 12:38:55"><buginformation><summary>[ZOOKEEPER-1181] Fix problems with Kerberos TGT renewal - ASF JIRA</summary><description>Currently, in Zookeeper trunk, there are two problems with Kerberos TGT renewal: 1. TGTs obtained from a keytab are not refreshed periodically. They should be, just as those from ticket cache are refreshed. 2. Ticket renewal should be retried if it fails. Ticket renewal might fail if two or more separate processes (different JVMs) running as the same user try to renew Kerberos credentials at the same time.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.Login.java</file></fixedFiles></bug><bug fixdate="2011-09-30 11:02:40" id="1174" opendate="2011-09-08 07:47:42"><buginformation><summary>[ZOOKEEPER-1174] FD leak when network unreachable - ASF JIRA</summary><description>In the socket connection logic there are several errors that result in bad behavior. The basic problem is that a socket is registered with a selector unconditionally when there are nuances that should be dealt with. First, the socket may connect immediately. Secondly, the connect may throw an exception. In either of these two cases, I don't think that the socket should be registered. I will attach a test case that demonstrates the problem. I have been unable to create a unit test that exhibits the problem because I would have to mock the low level socket libraries to do so. It would still be good to do so if somebody can figure out a good way.</description></buginformation><fixedFiles><file>a.src.java.main.org.apache.zookeeper.ClientCnxnSocketNIO.java</file><file>src.java.main.org.apache.zookeeper.ClientCnxn.java</file><file>a.src.java.main.org.apache.zookeeper.ClientCnxn.java</file><file>src.java.main.org.apache.zookeeper.ClientCnxnSocketNIO.java</file><file>a.src.java.main.org.apache.zookeeper.server.DataTree.java</file><file>src.java.main.org.apache.zookeeper.server.DataTree.java</file></fixedFiles></bug><bug fixdate="2011-09-01 06:15:50" id="1168" opendate="2011-08-31 08:52:13"><buginformation><summary>[ZOOKEEPER-1168] ZooKeeper fails to run with IKVM - ASF JIRA</summary><description>OS: Windows 64-bit JRE: IKVM 7.0.4258 IKVM 7.0.4258 does not support ManagementFactory.getPlatformMBeanServer(); It will throw a java.lang.Error.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.jmx.ManagedUtil.java</file><file>src.java.test.org.apache.zookeeper.test.JMXEnv.java</file><file>src.java.main.org.apache.zookeeper.jmx.MBeanRegistry.java</file></fixedFiles></bug><bug fixdate="2011-09-02 06:02:49" id="1165" opendate="2011-08-29 11:08:07"><buginformation><summary>[ZOOKEEPER-1165] better eclipse support in tests - ASF JIRA</summary><description>The Eclipse test runner tries to run tests from all classes that inherit from TestCase. However, this class is inherited by at least one class (org.apache.zookeeper.test.system.BaseSysTest) that has no test cases as it is used as infrastructure for other real test cases. This patch annotates that class with @Ignore, which causes the class to be Ignored. Also, due to the way annotations are not inherited by default, this patch will not affect classes that inherit from this class.</description></buginformation><fixedFiles><file>src.java.systest.org.apache.zookeeper.test.system.BaseSysTest.java</file></fixedFiles></bug><bug fixdate="2011-09-05 09:04:35" id="1156" opendate="2011-08-18 06:48:07"><buginformation><summary>[ZOOKEEPER-1156] Log truncation truncating log too much - can cause data loss - ASF JIRA</summary><description>The log truncation relies on position calculation for a particular zxid to figure out the new size of the log file. There is a bug in PositionInputStream implementation which skips counting the bytes in the log which have value 0. This can lead to underestimating the actual log size. The log records which should be there can get truncated, leading to data loss on the participant which is executing the trunc. Clients can see different values depending on whether they connect to the node on which trunc was executed.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.persistence.FileTxnLog.java</file></fixedFiles></bug><bug fixdate="2011-09-05 09:04:21" id="1154" opendate="2011-08-15 06:36:07"><buginformation><summary>[ZOOKEEPER-1154] Data inconsistency when the node(s) with the highest zxid is not present at the time of leader election - ASF JIRA</summary><description>If a participant with the highest zxid (lets call it A) isn't present during leader election, a participant with a lower zxid (say B) might be chosen as a leader. When A comes up, it will replay the log with that higher zxid. The change that was in that higher zxid will only be visible to the clients connecting to the participant A, but not to other participants. I was able to reproduce this problem by 1. connect debugger to B and C and suspend them, so they don't write anything 2. Issue an update to the leader A. 3. After a few seconds, crash all servers (A,B,C) 4. Start B and C, let the leader election take place 5. Start A. 6. You will find that the update done in step 2 is visible on A but not on B,C, hence the inconsistency. Below is a more detailed analysis of what is happening in the code. Initial Condition 1. Lets say there are three nodes in the ensemble A,B,C with A being the leader 2. The current epoch is 7. 3. For simplicity of the example, lets say zxid is a two digit number, with epoch being the first digit. 4. The zxid is 73 5. All the nodes have seen the change 73 and have persistently logged it. Step 1 Request with zxid 74 is issued. The leader A writes it to the log but there is a crash of the entire ensemble and B,C never write the change 74 to their log. Step 3 B,C restart, A is still down B,C form the quorum B is the new leader. Lets say B minCommitLog is 71 and maxCommitLog is 73 epoch is now 8, zxid is 80 Request with zxid 81 is successful. On B, minCommitLog is now 71, maxCommitLog is 81 Step 4 A starts up. It applies the change in request with zxid 74 to its in-memory data tree A contacts B to registerAsFollower and provides 74 as its ZxId Since 71&lt;=74&lt;=81, B decides to send A the diff. B will send to A the proposal 81. Problem: The problem with the above sequence is that A's data tree has the update from request 74, which is not correct. Before getting the proposals 81, A should have received a trunc to 73. I don't see that in the code. If the maxCommitLog on B hadn't bumped to 81 but had stayed at 73, that case seems to be fine.</description></buginformation><fixedFiles><file>src.java.test.org.apache.zookeeper.server.quorum.QuorumPeerMainTest.java</file><file>src.java.main.org.apache.zookeeper.server.persistence.FileTxnLog.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.Learner.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.LearnerHandler.java</file><file>src.java.test.org.apache.zookeeper.server.quorum.QuorumPeerTestBase.java</file></fixedFiles></bug><bug fixdate="2011-08-21 02:05:50" id="1152" opendate="2011-08-12 09:27:37"><buginformation><summary>[ZOOKEEPER-1152] Exceptions thrown from handleAuthentication can cause buffer corruption issues in NIOServer - ASF JIRA</summary><description>Exceptions thrown by an AuthenticationProvider's handleAuthentication method will not be caught, and can cause the buffers in the NIOServer to not read requests fully or properly. Any exceptions thrown here should be caught and treated as auth failure.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.ZooKeeperServer.java</file><file>src.java.test.org.apache.zookeeper.test.AuthTest.java</file></fixedFiles></bug><bug fixdate="2011-08-11 07:10:08" id="1144" opendate="2011-08-03 11:35:49"><buginformation><summary>[ZOOKEEPER-1144] ZooKeeperServer not starting on leader due to a race condition - ASF JIRA</summary><description>I have found one problem that is causing QuorumPeerMainTest:testQuorum to fail. This test uses 2 ZK servers. The test is failing because leader is not starting ZooKeeperServer after leader election. so everything halts. With the new changes, the server is now started in Leader.processAck() which is called from LeaderHandler. processAck() starts ZooKeeperServer if majority have acked NEWLEADER. The leader puts its ack in the the ackSet in Leader.lead(). Since processAck() is called from LearnerHandler it can happen that the learner's ack is processed before the leader is able to put its ack in the ackSet. When LearnerHandler invokes processAck(), the ackSet for newLeaderProposal will not have quorum (in this case 2). As a result, the ZooKeeperServer is never started on the Leader. The leader needs to ensure that its ack is put in ackSet before starting LearnerCnxAcceptor or invoke processAck() itself after adding to ackSet. I haven't had time to go through the ZAB2 changes so I am not too familiar with the code. Can Ben/Flavio fix this?</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.Leader.java</file></fixedFiles></bug><bug fixdate="2011-08-11 07:00:40" id="1142" opendate="2011-08-03 01:29:06"><buginformation><summary>[ZOOKEEPER-1142] incorrect stat output - ASF JIRA</summary><description>stat output seems to be missing some end of line: echo stat |nc c0309 2181&#13;
Zookeeper version: 3.4.0--1, built on 08/02/2011 22:25 GMT&#13;
Clients:&#13;
 /172.29.81.91:33378[0](queued=0,recved=1,sent=0&#13;
Latency min/avg/max: 0/28/252&#13;
Received: 246844&#13;
Sent: 266737&#13;
Outstanding: 0&#13;
Zxid: 0x4000508c2&#13;
Mode: follower&#13;
Node count: 4&#13;
 Multiple clients end up on the same line (missing newline)</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.NIOServerCnxn.java</file><file>src.java.test.org.apache.zookeeper.test.FourLetterWordsTest.java</file><file>src.java.main.org.apache.zookeeper.server.ServerCnxn.java</file><file>src.java.main.org.apache.zookeeper.server.NettyServerCnxn.java</file></fixedFiles></bug><bug fixdate="2011-08-30 07:37:27" id="1140" opendate="2011-07-29 05:49:37"><buginformation><summary>[ZOOKEEPER-1140] server shutdown is not stopping threads - ASF JIRA</summary><description>Near the end of QuorumZxidSyncTest there are tons of threads running - 115 "ProcessThread" threads, similar numbers of SessionTracker. Also I see ~100 ReadOnlyRequestProcessor - why is this running as a separate thread? (henry/flavio?)</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.ReadOnlyZooKeeperServer.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.QuorumPeer.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.LearnerHandler.java</file></fixedFiles></bug><bug fixdate="2011-07-29 12:23:57" id="1139" opendate="2011-07-27 10:42:05"><buginformation><summary>[ZOOKEEPER-1139] jenkins is reporting two warnings, fix these - ASF JIRA</summary><description>cleanup jenkins report, currently 2 compiler warnings being reported.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.Op.java</file><file>src.java.main.org.apache.zookeeper.ClientWatchManager.java</file></fixedFiles></bug><bug fixdate="2011-07-28 11:06:09" id="1138" opendate="2011-07-27 09:04:23"><buginformation><summary>[ZOOKEEPER-1138] release audit failing for a number of new files - ASF JIRA</summary><description>I'm seeing a number of problems in the release audit output for 3.4.0, these must be fixed before 3.4.0 release: [rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/contrib/ZooInspector/config/defaultConnectionSettings.cfg&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/contrib/ZooInspector/config/defaultNodeVeiwers.cfg&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/contrib/ZooInspector/licences/epl-v10.html&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/c/Cli.vcproj&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/c/include/winconfig.h&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/c/include/winstdint.h&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/c/zookeeper.sln&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/c/zookeeper.vcproj&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/huebrowser/zkui/src/zkui/static/help/index.html&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/huebrowser/zkui/src/zkui/static/js/package.yml&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/log4j.properties&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/date.format.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/g.bar.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/g.dot.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/g.line.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/g.pie.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/g.raphael.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/raphael.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/loggraph/web/org/apache/zookeeper/graph/resources/yui-min.js&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/monitoring/JMX-RESOURCES&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/zooinspector/config/defaultConnectionSettings.cfg&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/zooinspector/config/defaultNodeVeiwers.cfg&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/zooinspector/lib/log4j.properties&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/contrib/zooinspector/licences/epl-v10.html&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/java/test/org/apache/zookeeper/MultiTransactionRecordTest.java&#13;
[rat:report]  !????? /grid/0/hudson/hudson-slave/workspace/PreCommit-ZOOKEEPER-Build/trunk/build/zookeeper-3.4.0/src/java/test/org/apache/zookeeper/server/quorum/LearnerTest.java&#13;
Lines that start with ????? in the release audit report indicate files that do not have an Apache license header.</description></buginformation><fixedFiles><file>src.java.test.org.apache.zookeeper.MultiTransactionRecordTest.java</file><file>src.java.test.org.apache.zookeeper.server.quorum.LearnerTest.java</file></fixedFiles></bug><bug fixdate="2011-09-14 07:59:35" id="1136" opendate="2011-07-26 05:58:51"><buginformation><summary>[ZOOKEEPER-1136] NEW_LEADER should be queued not sent to match the Zab 1.0 protocol on the twiki - ASF JIRA</summary><description>the NEW_LEADER message was sent at the beginning of the sync phase in Zab pre1.0, but it must be at the end in Zab 1.0. if the protocol is 1.0 or greater we need to queue rather than send the packet.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.Leader.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.Learner.java</file><file>src.java.main.org.apache.zookeeper.server.FinalRequestProcessor.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.LearnerHandler.java</file><file>src.java.main.org.apache.zookeeper.server.PrepRequestProcessor.java</file><file>src.java.main.org.apache.zookeeper.server.ZooKeeperServer.java</file><file>src.java.main.org.apache.zookeeper.server.ByteBufferInputStream.java</file><file>src.java.main.org.apache.zookeeper.server.DataTree.java</file><file>src.java.test.org.apache.zookeeper.test.LETest.java</file></fixedFiles></bug><bug fixdate="2011-07-25 10:32:33" id="1134" opendate="2011-07-22 11:18:55"><buginformation><summary>[ZOOKEEPER-1134] ClientCnxnSocket string comparison using == rather than equals - ASF JIRA</summary><description>Noticed string comparison using == rather than equals.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.quorum.LeaderElection.java</file><file>src.java.main.org.apache.zookeeper.server.NIOServerCnxn.java</file><file>src.java.main.org.apache.zookeeper.server.WatchManager.java</file><file>src.java.main.org.apache.zookeeper.server.NettyServerCnxn.java</file><file>src.java.main.org.apache.zookeeper.ClientCnxnSocket.java</file></fixedFiles></bug><bug fixdate="2011-07-15 05:51:26" id="1124" opendate="2011-07-13 05:17:58"><buginformation><summary>[ZOOKEEPER-1124] Multiop submitted to non-leader always fails due to timeout - ASF JIRA</summary><description>The new Multiop support added under zookeeper-965 fails every single time if the multiop is submitted to a non-leader in quorum mode. In standalone mode it always works properly and this bug only presents itself in quorum mode (with 2 or more nodes). After 12 hours of debugging (sigh) it turns out to be a really simple fix. There are a couple of missing case statements inside FollowerRequestProcessor.java and ObserverRequestProcessor.java to ensure that multiop is forwarded to the leader for commit. I've attached a patch that fixes this problem. It's probably worth nothing that zookeeper-965 has already been committed to trunk. But this is a fatal flaw that will prevent multiop support from working properly and as such needs to get committed to 3.4.0 as well. Is there a way to tie these two cases together in some way?</description></buginformation><fixedFiles><file>src_new.src.java.test.org.apache.zookeeper.test.QuorumTest.java</file><file>src.java.test.org.apache.zookeeper.test.QuorumTest.java</file><file>src_new.src.java.main.org.apache.zookeeper.server.quorum.FollowerRequestProcessor.java</file><file>src_new.src.java.main.org.apache.zookeeper.server.quorum.ObserverRequestProcessor.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.ObserverRequestProcessor.java</file><file>src.java.main.org.apache.zookeeper.server.quorum.FollowerRequestProcessor.java</file></fixedFiles></bug><bug fixdate="2011-07-25 10:01:11" id="1109" opendate="2011-06-24 05:48:18"><buginformation><summary>[ZOOKEEPER-1109] Zookeeper service is down when SyncRequestProcessor meets any exception. - ASF JIRA</summary><description>Problem Zookeeper is not shut down completely when dataDir disk space is full and ZK Cluster went into unserviceable state. Scenario If the leader zookeeper disk is made full, the zookeeper is trying to shutdown. But it is waiting indefinitely while shutting down the SyncRequestProcessor thread. Root Cause this.join() is invoked in the same thread where System.exit(11) has been triggered. When disk space full happens, It got the exception as follows 'No space left on device' and invoked System.exit(11) from the SyncRequestProcessor thread(The following logs shows the same). Before exiting JVM, ZK will execute the ShutdownHook of QuorumPeerMain and the flow comes to SyncRequestProcessor.shutdown(). Here this.join() is invoked in the same thread where System.exit(11) has been invoked.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.SyncRequestProcessor.java</file></fixedFiles></bug><bug fixdate="2011-09-09 03:27:39" id="1108" opendate="2011-06-23 10:02:34"><buginformation><summary>[ZOOKEEPER-1108] Various bugs in zoo_add_auth in C - ASF JIRA</summary><description>3 issues: In zoo_add_auth: there is a race condition: 2940 // ZOOKEEPER-800 zoo_add_auth should return ZINVALIDSTATE if 2941 // the connection is closed. 2942 if (zoo_state(zh) == 0) { 2943 return ZINVALIDSTATE; 2944 } when we do zookeeper_init, the state is initialized to 0 and above we check if state = 0 then throw exception. There is a race condition where the doIo thread is slow and has not changed the state to CONNECTING, then you end up returning back ZKINVALIDSTATE. The problem is we use 0 for CLOSED state and UNINITIALIZED state. in case of uninitialized case it should let it go through. 2nd issue: Another Bug: in send_auth_info, the check is not correct while (auth-&gt;next != NULL) { //--BUG: in cases where there is only one auth in the list, this will never send that auth, as its next will be NULL rc = send_info_packet(zh, auth); auth = auth-&gt;next; } FIX IS: do { rc = send_info_packet(zh, auth); auth = auth-&gt;next; } while (auth != NULL); //this will make sure that even if there is one auth ,that will get sent. 3rd issue: 2965 add_last_auth(&amp;zh-&gt;auth_h, authinfo); 2966 zoo_unlock_auth(zh); 2967 2968 if(zh-&gt;state == ZOO_CONNECTED_STATE || zh-&gt;state == ZOO_ASSOCIATING_STATE) 2969 return send_last_auth_info(zh); if it is connected, we only send the last_auth_info, which may be different than the one we added, as we unlocked it before sending it.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.ClientCnxn.java</file><file>src.java.main.org.apache.zookeeper.ZooKeeper.java</file></fixedFiles></bug><bug fixdate="2011-06-27 12:30:59" id="1097" opendate="2011-06-16 03:07:44"><buginformation><summary>[ZOOKEEPER-1097] Quota is not correctly rehydrated on snapshot reload - ASF JIRA</summary><description>traverseNode in DataTree will never actually traverse the limit nodes properly.</description></buginformation><fixedFiles><file>a.src.java.test.org.apache.zookeeper.test.ZooKeeperQuotaTest.java</file><file>src.java.test.org.apache.zookeeper.test.ZooKeeperQuotaTest.java</file><file>a.src.java.main.org.apache.zookeeper.server.DataTree.java</file><file>src.java.main.org.apache.zookeeper.server.DataTree.java</file></fixedFiles></bug><bug fixdate="2011-06-21 06:34:27" id="1087" opendate="2011-06-06 09:09:54"><buginformation><summary>[ZOOKEEPER-1087] ForceSync VM arguement not working when set to "no" - ASF JIRA</summary><description>Cannot use forceSync=no to asynchronously write transaction logs. This is a critical bug, please address it ASAP. More details: The class org.apache.zookeeper.server.persistence.FileTxnLog initializes forceSync property in a static block. However, the static variable is defined after the static block with a default value of true. Therefore, the value of the variable can never be false. Please move the declaration of the variable before the static block.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.persistence.FileTxnLog.java</file><file>src.java.test.org.apache.zookeeper.server.ZooKeeperServerTest.java</file></fixedFiles></bug><bug fixdate="2011-07-29 09:14:46" id="1076" opendate="2011-05-25 11:19:48"><buginformation><summary>[ZOOKEEPER-1076] some quorum tests are unnecessarily extending QuorumBase - ASF JIRA</summary><description>Some tests are unnecessarily extending QuorumBase. Typically this is not a big issue, but it may cause more servers than necessary to be started (harder to debug a failing test in particular).</description></buginformation><fixedFiles><file>src.java.test.org.apache.zookeeper.test.QuorumHammerTest.java</file><file>src.java.test.org.apache.zookeeper.test.QuorumTest.java</file><file>src.java.test.org.apache.zookeeper.test.ReadOnlyModeTest.java</file><file>src.java.test.org.apache.zookeeper.test.FollowerResyncConcurrencyTest.java</file><file>src.java.test.org.apache.zookeeper.test.ZkDatabaseCorruptionTest.java</file></fixedFiles></bug><bug fixdate="2011-07-17 03:36:48" id="1069" opendate="2011-05-24 12:53:31"><buginformation><summary>[ZOOKEEPER-1069] Calling shutdown() on a QuorumPeer too quickly can lead to a corrupt log - ASF JIRA</summary><description>I've only seen this happen once. In order to restart Zookeeper with a new set of servers, we have a wrapper class that calls shutdown() on an existing QuorumPeer, and then starts a new one with a new set of servers. Specifically, our shutdown code looks like this: &#13;
  synchronized(_quorum_peer) {&#13;
    _quorum_peer.shutdown();&#13;
    FastLeaderElection fle = (FastLeaderElection) _quorum_peer.getElectionAlg();&#13;
    fle.shutdown();  // I think this is unnecessary&#13;
    try {&#13;
      _quorum_peer.getTxnFactory().commit();&#13;
    } catch (java.nio.channels.ClosedChannelException e) {&#13;
      // ignore&#13;
    }&#13;
  }&#13;
 One time, our wrapper class started one QuorumPeer, and then had to shut it down and start a new one very soon after the QuorumPeer transitioned into a FOLLOWING state. When the new QuorumPeer tried to read in the latest log from disk, it encountered a bogus magic number of all zeroes: 2011-05-18 22:42:29,823 10467 [pool-1-thread-2] FATAL org.apache.zookeeper.server.quorum.QuorumPeer  - Unable to load database on disk&#13;
java.io.IOException: Transaction log: /var/cloudnet/data/zookeeper/version-2/log.700000001 has invalid magic number 0 != 1514884167&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.inStreamCreated(FileTxnLog.java:510)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.createInputArchive(FileTxnLog.java:527)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.goToNextLog(FileTxnLog.java:493)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.next(FileTxnLog.java:576)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.init(FileTxnLog.java:479)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.&lt;init&gt;(FileTxnLog.java:454)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog.read(FileTxnLog.java:325)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:126)&#13;
        at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:222)&#13;
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:398)&#13;
...&#13;
2011-05-18 22:42:29,823 10467 [pool-1-thread-2] ERROR com.nicira.onix.zookeeper.Zookeeper  - Unexpected exception&#13;
java.lang.RuntimeException: Unable to run quorum server &#13;
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:401)&#13;
        at com.nicira.onix.zookeeper.Zookeeper.StartZookeeper(Zookeeper.java:198)&#13;
        at com.nicira.onix.zookeeper.Zookeeper.RestartZookeeper(Zookeeper.java:277)&#13;
        at com.nicira.onix.zookeeper.ZKRPCService.setServers(ZKRPC.java:83)&#13;
        at com.nicira.onix.zookeeper.Zkrpc$ZKRPCService.callMethod(Zkrpc.java:8198)&#13;
        at com.nicira.onix.rpc.RPC$10.run(RPC.java:534)&#13;
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)&#13;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)&#13;
        at java.lang.Thread.run(Thread.java:662)&#13;
Caused by: java.io.IOException: Transaction log: /var/cloudnet/data/zookeeper/version-2/log.700000001 has invalid magic number 0 != 1514884167&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.inStreamCreated(FileTxnLog.java:510)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.createInputArchive(FileTxnLog.java:527)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.goToNextLog(FileTxnLog.java:493)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.next(FileTxnLog.java:576)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.init(FileTxnLog.java:479)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog$FileTxnIterator.&lt;init&gt;(FileTxnLog.java:454)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnLog.read(FileTxnLog.java:325)&#13;
        at org.apache.zookeeper.server.persistence.FileTxnSnapLog.restore(FileTxnSnapLog.java:126)&#13;
        at org.apache.zookeeper.server.ZKDatabase.loadDataBase(ZKDatabase.java:222)&#13;
        at org.apache.zookeeper.server.quorum.QuorumPeer.start(QuorumPeer.java:398)&#13;
        ... 8 more&#13;
 I looked into the code a bit, and I believe the problem comes from the fact that QuorumPeer.shutdown() does not join() on this before returning. Here's the scenario I think can happen: QuorumPeer.run() notices it is in the FOLLOWING state, makes a new Follower, and calls Follower.followLeader(), which starts connecting to the leader. In the main program thread, QuorumPeer.shutdown() is called. Through a complicated series of calls, this eventually leads to FollowerZooKeeperServer.shutdown() being called. This method calls SyncRequestProcess.shutdown(), which joins on this and returns. However, it's possible that the SyncRequestProcessor thread hasn't yet been started because followLeader() hasn't yet called Learner.syncWithLeader(), which hasn't yet called ZooKeeperServer.startup(), which actually starts the thread. Thus, the join would have no request, though a requestOfDeath is added to the queued requests list (possibly behind other requests). Back in the main thread, FileTxnSnapLog.commit() is called, which doesn't do much because the processor hasn't processed anything yet. Finally, ZooKeeperServer.startup is called in the QuorumPeer.run() thread, starting up the SyncRequestProcessor thread. That thread appends some request to the log. The log doesn't exist yet, so it creates a new one, padding it with zeroes. Now either the SyncRequestProcessor hits the requestOfDeath or the whole QuorumPeer object is deleted. It exits that thread without ever committing the log to disk (or the new QuorumPeer tries to read the log before the old thread gets to commit anything), and the log ends up with all zeroes instead of a proper magic number. I haven't yet looked into whether there's an easy way to join() on the QuorumPeer thread from shutdown(), so that it won't go on to start the processor threads after it's been shutdown. I wanted to check with the group first and see if anyone else agrees this could be a problem. I marked this as minor since I think almost no one else uses Zookeeper this way, but it's pretty important to me personally. I will upload a log file showing this behavior shortly.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.server.persistence.FileTxnLog.java</file><file>src.java.test.org.apache.zookeeper.test.LoadFromLogTest.java</file></fixedFiles></bug><bug fixdate="2011-07-15 05:11:22" id="1063" opendate="2011-05-17 10:34:09"><buginformation><summary>[ZOOKEEPER-1063] Dubious synchronization in Zookeeper and ClientCnxnSocketNIO classes - ASF JIRA</summary><description>Synchronization around dataWatches, existWatches and childWatches in Zookeeper is incorrect. Synchronization around outgoingQueue and pendingQueue in ClientCnxnSocketNIO is incorrect. Synchronization around selector and key sets in ClientCnxnSocketNIO seems odd.</description></buginformation><fixedFiles><file>src.java.main.org.apache.zookeeper.ZooKeeper.java</file><file>src.java.main.org.apache.zookeeper.ClientCnxnSocketNIO.java</file></fixedFiles></bug></bugrepository>