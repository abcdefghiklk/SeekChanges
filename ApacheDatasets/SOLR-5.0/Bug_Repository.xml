<?xml version="1.0" encoding="UTF-8" standalone="no"?><bugrepository><bug fixdate="2015-01-27 01:46:10" id="7039" opendate="2015-01-26 10:03:26"><buginformation><summary>[SOLR-7039] First collection created with stateFormat=2 results in a weird /clusterstate.json - ASF JIRA</summary><description>With the 5.0 branch, when I do: &#13;
bin/solr -c &amp;&amp; bin/solr create -c foo&#13;
 The /clusterstate.json in ZK has and invalid definition of the foo collection &#13;
{"foo":{&#13;
    "replicationFactor":"1",&#13;
    "router":{"name":"compositeId"},&#13;
    "maxShardsPerNode":"1",&#13;
    "autoAddReplicas":"false",&#13;
    "shards":{"shard1":{&#13;
        "range":"80000000-7fffffff",&#13;
        "state":"active",&#13;
        "replicas":{}}}}}&#13;
 To verify this isn't the UI sending back the wrong data, I went into the zkCli.sh command-line and got: &#13;
[zk: localhost:9983(CONNECTED) 2] get /clusterstate.json&#13;
{"foo":{&#13;
    "replicationFactor":"1",&#13;
    "router":{"name":"compositeId"},&#13;
    "maxShardsPerNode":"1",&#13;
    "autoAddReplicas":"false",&#13;
    "shards":{"shard1":{&#13;
        "range":"80000000-7fffffff",&#13;
        "state":"active",&#13;
        "replicas":{}}}}}&#13;
cZxid = 0x20&#13;
ctime = Mon Jan 26 14:56:44 MST 2015&#13;
mZxid = 0x65&#13;
mtime = Mon Jan 26 14:57:16 MST 2015&#13;
pZxid = 0x20&#13;
cversion = 0&#13;
dataVersion = 1&#13;
aclVersion = 0&#13;
ephemeralOwner = 0x0&#13;
dataLength = 247&#13;
numChildren = 0&#13;
 The /collections/foo/state.json looks correct: &#13;
{"foo":{&#13;
    "replicationFactor":"1",&#13;
    "router":{"name":"compositeId"},&#13;
    "maxShardsPerNode":"1",&#13;
    "autoAddReplicas":"false",&#13;
    "shards":{"shard1":{&#13;
        "range":"80000000-7fffffff",&#13;
        "state":"active",&#13;
        "replicas":{"core_node1":{&#13;
            "core":"foo_shard1_replica1",&#13;
            "base_url":"http://192.168.1.2:8983/solr",&#13;
            "node_name":"192.168.1.2:8983_solr",&#13;
            "state":"active",&#13;
            "leader":"true"}}}}}}&#13;
 Here's the weird thing ... If I create a second collection using the same script, all is well and /clusterstate.json is empty &#13;
bin/solr create -c foo2&#13;
 Calling this a blocker because 5.0 can't be released with this happening.</description></buginformation><fixedFiles><file>solr.solrj.src.java.org.apache.solr.common.cloud.ClusterState.java</file><file>solr.core.src.java.org.apache.solr.cloud.overseer.ZkStateWriter.java</file><file>solr.core.src.test.org.apache.solr.cloud.overseer.ZkStateWriterTest.java</file></fixedFiles></bug><bug fixdate="2015-02-26 11:08:22" id="7038" opendate="2015-01-26 07:29:03"><buginformation><summary>[SOLR-7038] If no configset exists, CREATE leads to a 500 error with never-ending logging and 100% CPU usage - ASF JIRA</summary><description>Here's what I did: &#13;
&gt; bin/solr start -e cloud -noprompt&#13;
&#13;
&gt; curl http://localhost:8983/solr/admin/collections?action=CREATE&amp;name=thisshouldfail&amp;numShards=1&amp;configset=thisisaninvalidconfigset&amp;wt=json&#13;
 The above led to a new collection named thisshouldfail, with the config-set as gettingstarted. This call should have failed as there was no configset by that name. Instead, it picked up the only config set it found and used it. There's more to this. I'm not sure how related this is but looks like it to me. &#13;
&gt; bin/solr start -c&#13;
&#13;
&gt; curl http://localhost:8983/solr/admin/collections?action=CREATE&amp;name=thisshouldfail&amp;numShards=1&amp;configset=thisisaninvalidconfigset&amp;wt=json&#13;
 This led to a 900M (and growing) log file in addition to 100% CPU until I killed Solr.</description></buginformation><fixedFiles><file>solr.core.src.test.org.apache.solr.cloud.OverseerCollectionProcessorTest.java</file><file>solr.core.src.java.org.apache.solr.cloud.OverseerCollectionProcessor.java</file></fixedFiles></bug><bug fixdate="2015-02-27 06:46:49" id="7033" opendate="2015-01-26 03:29:23"><buginformation><summary>[SOLR-7033] RecoveryStrategy should not publish any state when closed / cancelled. - ASF JIRA</summary><description>Currently, when closed / cancelled, RecoveryStrategy can publish a recovery failed state. In a bad loop (like when no one can become leader because no one had a last state of active) this can cause very fast looped publishing of this state to zk. It's an outstanding item to improve that specific scenario anyway, but regardless, we should fix the close / cancel path to never publish any state to zk.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.cloud.ElectionContext.java</file><file>solr.core.src.java.org.apache.solr.update.DefaultSolrCoreState.java</file><file>solr.core.src.java.org.apache.solr.update.SolrCoreState.java</file><file>solr.core.src.java.org.apache.solr.cloud.ActionThrottle.java</file><file>solr.core.src.test.org.apache.solr.cloud.ActionThrottleTest.java</file><file>solr.core.src.java.org.apache.solr.cloud.RecoveryThrottle.java</file><file>solr.core.src.java.org.apache.solr.cloud.RecoveryStrategy.java</file><file>solr.core.src.test.org.apache.solr.cloud.RecoveryThrottleTest.java</file></fixedFiles></bug><bug fixdate="2015-03-02 04:46:15" id="6969" opendate="2015-01-12 06:05:07"><buginformation><summary>[SOLR-6969] When opening an HDFSTransactionLog for append we must first attempt to recover it's lease to prevent data loss. - ASF JIRA</summary><description>This can happen after a hard crash and restart. The current workaround is to stop and wait it out and start again. We should retry and wait a given amount of time as we do when we detect safe mode though.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.update.HdfsUpdateLog.java</file><file>solr.core.src.java.org.apache.solr.util.FSHDFSUtils.java</file><file>solr.core.src.test.org.apache.solr.cloud.hdfs.HdfsTestUtil.java</file><file>solr.core.src.java.org.apache.solr.update.HdfsTransactionLog.java</file><file>solr.core.src.test.org.apache.solr.cloud.hdfs.HdfsCollectionsAPIDistributedZkTest.java</file></fixedFiles></bug><bug fixdate="2015-05-05 02:41:38" id="6952" opendate="2015-01-10 03:32:24"><buginformation><summary>[SOLR-6952] Re-using data-driven configsets by default is not helpful - ASF JIRA</summary><description>When creating collections (I'm using the bin/solr scripts), I think we should automatically copy configsets, especially when running in "getting started mode" or data driven mode. I did the following: &#13;
bin/solr create_collection -n foo&#13;
bin/post foo some_data.csv&#13;
 I then created a second collection with the intention of sending in the same data, but this time run through a python script that changed a value from an int to a string (since it was an enumerated type) and was surprised to see that I got: Caused by: java.lang.NumberFormatException: For input string: "NA" at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65) at java.lang.Long.parseLong(Long.java:441) for my new version of the data that passes in a string instead of an int, as this new collection had only seen strings for that field.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.util.SolrCLI.java</file></fixedFiles></bug><bug fixdate="2015-02-26 03:17:13" id="6941" opendate="2015-01-09 03:56:38"><buginformation><summary>[SOLR-6941] DistributedQueue#containsTaskWithRequestId can fail with NPE. - ASF JIRA</summary><description>I've seen this happen some recently. Seems data can be return as null and we need to guard against it.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.cloud.DistributedQueue.java</file></fixedFiles></bug><bug fixdate="2015-01-14 08:08:44" id="6937" opendate="2015-01-09 03:02:37"><buginformation><summary>[SOLR-6937] In schemaless mode ,replace spaces and special characters in field names with underscore - ASF JIRA</summary><description>Assuming spaces in field names are still bad, we should automatically convert them to not have spaces. For instance, I indexed Citibike public data set which has: "tripduration","starttime","stoptime","start station id","start station name","start station latitude","start station longitude","end station id","end station name","end station latitude","end station longitude","bikeid","usertype","birth year","gender" My vote would be to replace spaces w/ underscores.</description></buginformation><fixedFiles><file>solr.solrj.src.test.org.apache.solr.client.solrj.SolrExampleTestsBase.java</file><file>solr.core.src.java.org.apache.solr.update.processor.FieldNameMutatingUpdateProcessorFactory.java</file><file>solr.solrj.src.test.org.apache.solr.client.solrj.SolrSchemalessExampleTest.java</file></fixedFiles></bug><bug fixdate="2015-01-10 04:00:34" id="6932" opendate="2015-01-08 05:49:19"><buginformation><summary>[SOLR-6932] All HttpClient ConnectionManagers and SolrJ clients should always be shutdown in tests and regular code. - ASF JIRA</summary><description/></buginformation><fixedFiles><file>solr.core.src.test.org.apache.solr.cloud.ChaosMonkeyNothingIsSafeTest.java</file><file>solr.core.src.test.org.apache.solr.rest.schema.TestManagedSchemaDynamicFieldResource.java</file><file>solr.core.src.test.org.apache.solr.rest.schema.analysis.TestManagedStopFilterFactory.java</file><file>solr.contrib.dataimporthandler.src.test.org.apache.solr.handler.dataimport.TestContentStreamDataSource.java</file><file>solr.core.src.test.org.apache.solr.handler.TestBlobHandler.java</file><file>solr.core.src.java.org.apache.solr.core.CoreContainer.java</file><file>solr.core.src.java.org.apache.solr.update.processor.DistributedUpdateProcessor.java</file><file>solr.core.src.test.org.apache.solr.rest.schema.TestBulkSchemaAPI.java</file><file>solr.core.src.test.org.apache.solr.handler.TestReplicationHandler.java</file><file>solr.core.src.test.org.apache.solr.core.TestSolrConfigHandler.java</file><file>solr.core.src.test.org.apache.solr.rest.schema.TestManagedSchemaFieldTypeResource.java</file><file>solr.core.src.java.org.apache.solr.cloud.Overseer.java</file><file>solr.core.src.test.org.apache.solr.cloud.LeaderFailoverAfterPartitionTest.java</file><file>solr.core.src.test.org.apache.solr.core.TestDynamicLoading.java</file><file>solr.core.src.java.org.apache.solr.util.IOUtils.java</file><file>solr.core.src.test.org.apache.solr.core.TestCoreDiscovery.java</file><file>solr.core.src.java.org.apache.solr.core.HdfsDirectoryFactory.java</file><file>solr.core.src.java.org.apache.solr.store.hdfs.HdfsDirectory.java</file><file>solr.core.src.test.org.apache.solr.schema.TestCloudSchemaless.java</file><file>solr.contrib.dataimporthandler.src.java.org.apache.solr.handler.dataimport.SolrEntityProcessor.java</file><file>solr.core.src.java.org.apache.solr.store.hdfs.HdfsLockFactory.java</file><file>solr.core.src.test.org.apache.solr.handler.TestSolrConfigHandlerConcurrent.java</file><file>solr.core.src.test.org.apache.solr.cloud.SolrXmlInZkTest.java</file><file>solr.core.src.java.org.apache.solr.update.UpdateShardHandler.java</file><file>solr.core.src.java.org.apache.solr.update.SolrIndexWriter.java</file><file>solr.core.src.test.org.apache.solr.cloud.OverseerTest.java</file><file>solr.core.src.test.org.apache.solr.search.AnalyticsMergeStrategyTest.java</file><file>solr.core.src.test.org.apache.solr.schema.TestBulkSchemaConcurrent.java</file><file>solr.core.src.java.org.apache.solr.update.PeerSync.java</file><file>solr.core.src.test.org.apache.solr.rest.schema.analysis.TestManagedSynonymFilterFactory.java</file><file>solr.core.src.test.org.apache.solr.rest.schema.TestManagedSchemaFieldResource.java</file><file>solr.core.src.test.org.apache.solr.search.TestRecoveryHdfs.java</file><file>solr.core.src.java.org.apache.solr.handler.SnapPuller.java</file><file>solr.core.src.test.org.apache.solr.handler.TestConfigReload.java</file><file>solr.core.src.test.org.apache.solr.cloud.CollectionsAPIDistributedZkTest.java</file><file>solr.core.src.test.org.apache.solr.schema.TestBinaryField.java</file><file>solr.core.src.test.org.apache.solr.cloud.AliasIntegrationTest.java</file><file>solr.core.src.java.org.apache.solr.servlet.SolrDispatchFilter.java</file><file>solr.core.src.java.org.apache.solr.util.SolrCLI.java</file><file>solr.core.src.java.org.apache.solr.update.HdfsUpdateLog.java</file><file>solr.core.src.test.org.apache.solr.cloud.MultiThreadedOCPTest.java</file><file>solr.core.src.test.org.apache.solr.schema.TestCloudManagedSchemaConcurrent.java</file><file>solr.contrib.dataimporthandler.src.test.org.apache.solr.handler.dataimport.TestSolrEntityProcessorUnit.java</file><file>solr.core.src.test.org.apache.solr.cloud.TestLeaderElectionZkExpiry.java</file><file>solr.core.src.test.org.apache.solr.cloud.TestRequestStatusCollectionAPI.java</file><file>solr.core.src.java.org.apache.solr.core.CoreDescriptor.java</file><file>solr.core.src.test.org.apache.solr.cloud.ZkControllerTest.java</file><file>solr.core.src.test.org.apache.solr.core.TestImplicitCoreProperties.java</file><file>solr.core.src.java.org.apache.solr.core.SolrCore.java</file><file>solr.core.src.test.org.apache.solr.cloud.LeaderInitiatedRecoveryOnCommitTest.java</file><file>solr.core.src.test.org.apache.solr.cloud.ShardSplitTest.java</file><file>solr.core.src.java.org.apache.solr.core.PluginInfo.java</file><file>solr.core.src.test.org.apache.solr.handler.TestSolrConfigHandlerCloud.java</file><file>solr.core.src.java.org.apache.solr.core.CorePropertiesLocator.java</file><file>solr.core.src.test.org.apache.solr.cloud.DeleteShardTest.java</file><file>solr.core.src.test.org.apache.solr.cloud.CollectionsAPIAsyncDistributedZkTest.java</file><file>solr.core.src.test.org.apache.solr.cloud.CustomCollectionTest.java</file></fixedFiles></bug><bug fixdate="2015-01-15 04:19:52" id="6931" opendate="2015-01-08 05:36:50"><buginformation><summary>[SOLR-6931] We should do a limited retry when using HttpClient. - ASF JIRA</summary><description>This is likely the issue you are looking for if you are looking to solve random SocketException "connection reset" issues.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.update.UpdateShardHandler.java</file><file>solr.solrj.src.java.org.apache.solr.client.solrj.impl.HttpClientUtil.java</file><file>solr.core.src.java.org.apache.solr.handler.component.HttpShardHandlerFactory.java</file><file>solr.solrj.src.java.org.apache.solr.client.solrj.impl.HttpClientConfigurer.java</file><file>solr.solrj.src.java.org.apache.solr.client.solrj.impl.LBHttpSolrClient.java</file></fixedFiles></bug><bug fixdate="2015-01-08 06:42:47" id="6925" opendate="2015-01-07 06:47:18"><buginformation><summary>[SOLR-6925] Back out changes having to do with SOLR-5287 (editing configs from admin UI) - ASF JIRA</summary><description>Should have something today/tomorrow. The history here is that I had this bright idea to edit files directly from the admin UI, especially schema.xml and solrxconifg.xml. Brilliant I sez to myself... except it's a significant security hole and I'm really glad that was pointed out before we released it in 4x. So we pulled it completely from 4.x and made it something in 5.x (then trunk) that you could enable (disabled by default) if you wanted to live dangerously and "we'd deal with it later". Well it's later. Given all the work for managed schemas and the like in the interim, I think this is cruft that should be removed completely from current trunk and 5x. Marking it as a blocker so we don't release 5x with this in it or we'll have back-compat issues. Should have a fix in very quickly.</description></buginformation><fixedFiles><file>solr.core.src.test.org.apache.solr.schema.ModifyConfFileTest.java</file><file>solr.core.src.java.org.apache.solr.handler.admin.EditFileRequestHandler.java</file><file>solr.core.src.test.org.apache.solr.cloud.TestModifyConfFiles.java</file></fixedFiles></bug><bug fixdate="2015-09-18 01:17:27" id="6923" opendate="2015-01-07 12:14:03"><buginformation><summary>[SOLR-6923] AutoAddReplicas should consult live nodes also to see if a state has changed - ASF JIRA</summary><description>I did the following &#13;
./solr start -e cloud -noprompt&#13;
&#13;
kill -9 &lt;pid-of-node2&gt; //Not the node which is running ZK&#13;
 /live_nodes reflects that the node is gone. This is the only message which gets logged on the node1 server after killing node2 &#13;
45812 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:9983] WARN  org.apache.zookeeper.server.NIOServerCnxn  – caught end of stream exception&#13;
EndOfStreamException: Unable to read additional data from client sessionid 0x14ac40f26660001, likely client has closed socket&#13;
    at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)&#13;
    at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)&#13;
    at java.lang.Thread.run(Thread.java:745)&#13;
 The graph shows the node2 as 'Gone' state clusterstate.json keeps showing the replica as 'active' &#13;
{"collection1":{&#13;
    "shards":{"shard1":{&#13;
        "range":"80000000-7fffffff",&#13;
        "state":"active",&#13;
        "replicas":{&#13;
          "core_node1":{&#13;
            "state":"active",&#13;
            "core":"collection1",&#13;
            "node_name":"169.254.113.194:8983_solr",&#13;
            "base_url":"http://169.254.113.194:8983/solr",&#13;
            "leader":"true"},&#13;
          "core_node2":{&#13;
            "state":"active",&#13;
            "core":"collection1",&#13;
            "node_name":"169.254.113.194:8984_solr",&#13;
            "base_url":"http://169.254.113.194:8984/solr"}}}},&#13;
    "maxShardsPerNode":"1",&#13;
    "router":{"name":"compositeId"},&#13;
    "replicationFactor":"1",&#13;
    "autoAddReplicas":"false",&#13;
    "autoCreated":"true"}}&#13;
 One immediate problem I can see is that AutoAddReplicas doesn't work since the clusterstate.json never changes. There might be more features which are affected by this. On first thought I think we can handle this - The shard leader could listen to changes on /live_nodes and if it has replicas that were on that node, mark it as 'down' in the clusterstate.json?</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.cloud.OverseerAutoReplicaFailoverThread.java</file></fixedFiles></bug><bug fixdate="2015-02-09 06:50:19" id="6920" opendate="2015-01-07 07:23:14"><buginformation><summary>[SOLR-6920] During replication use checksums to verify if files are the same - ASF JIRA</summary><description>Currently we check if an index file on the master and slave is the same by checking if it's name and file length match. With LUCENE-2446 we now have a checksums for each index file in the segment. We should leverage this to verify if two files are the same. Places like SnapPuller.isIndexStale and SnapPuller.downloadIndexFiles should check against the checksum also.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.handler.SnapPuller.java</file><file>solr.core.src.java.org.apache.solr.handler.ReplicationHandler.java</file><file>solr.core.src.java.org.apache.solr.search.grouping.distributed.responseprocessor.TopGroupsShardResponseProcessor.java</file><file>solr.core.src.test.org.apache.solr.cloud.hdfs.HdfsTestUtil.java</file></fixedFiles></bug><bug fixdate="2015-01-04 07:14:06" id="6907" opendate="2015-01-03 04:10:40"><buginformation><summary>[SOLR-6907] URLEncode documents directory in MorphlineMapperTest to handle spaces etc. in file name - ASF JIRA</summary><description>Currently the test fails if the source is checked out on a directory whose path contains, say spaces..</description></buginformation><fixedFiles><file>solr.contrib.map-reduce.src.test.org.apache.solr.hadoop.MorphlineMapperTest.java</file></fixedFiles></bug><bug fixdate="2014-12-30 12:22:25" id="6899" opendate="2014-12-30 12:02:29"><buginformation><summary>[SOLR-6899] SolrJ CollectionAdminRequest classes should not support public setters for action - ASF JIRA</summary><description>There shouldn't be public action setters for the CollectionAdminRequests. To elaborate more, a Create object should be able to do just that, doesn't make sense to support/have the following: &#13;
Create c = new Create();&#13;
c.setAction("RELOAD");&#13;
 The implementation could have an action = &lt;custom action&gt; in case of custom actions.</description></buginformation><fixedFiles><file>solr.solrj.src.java.org.apache.solr.client.solrj.request.CollectionAdminRequest.java</file></fixedFiles></bug><bug fixdate="2014-12-23 11:35:52" id="6883" opendate="2014-12-23 07:06:39"><buginformation><summary>[SOLR-6883] CLUSTERPROP API switch case does not call break - ASF JIRA</summary><description>In the Overseer when handling the CLUSTERPROP case, break is not called which leads to the ADDREPLICAPROP API also getting invoked.</description></buginformation><fixedFiles><file>solr.core.src.java.org.apache.solr.cloud.Overseer.java</file></fixedFiles></bug><bug fixdate="2015-01-15 04:24:04" id="6880" opendate="2014-12-22 07:57:19"><buginformation><summary>[SOLR-6880] ZKStateReader makes a call to updateWatchedCollection, which doesn't accept null with a method creating the argument that can return null. - ASF JIRA</summary><description>I've seen the resulting NPE in tests.</description></buginformation><fixedFiles><file>solr.solrj.src.java.org.apache.solr.common.cloud.ZkStateReader.java</file></fixedFiles></bug><bug fixdate="2015-01-06 08:38:46" id="6874" opendate="2014-12-21 03:31:05"><buginformation><summary>[SOLR-6874] There is a race around SocketProxy binding to it's port the way we setup JettySolrRunner and SocketProxy. - ASF JIRA</summary><description>I ran into this while working on SOLR-4509 and have a fix there in my latest patch. Because we get an available port by opening and closing a scocket on port 0 and then try to use it again with the SocketProxy, sometimes it fails to bind and the test can fail. We can change the code a bit so that the SocketProxy itself can start on port 0 rather than this two step fragile process.</description></buginformation><fixedFiles><file>solr.core.src.test.org.apache.solr.cloud.ReplicationFactorTest.java</file><file>solr.test-framework.src.java.org.apache.solr.cloud.SocketProxy.java</file><file>solr.test-framework.src.java.org.apache.solr.cloud.AbstractFullDistribZkTestBase.java</file></fixedFiles></bug><bug fixdate="2015-12-07 07:05:35" id="6868" opendate="2014-12-18 11:52:17"><buginformation><summary>[SOLR-6868] Investigate failing CollectionsAPIDistributedZkTest - ASF JIRA</summary><description>CollectionsAPIDistributedZkTest has been failing (on trunk and 5x) off late. Running the following ant test -Dtestcase=CollectionsAPIDistributedZkTest -Dtests.method=testDistribSearch -Dtests.seed=8219942E65A94EC1 -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=nl -Dtests.timezone=America/Halifax -Dtests.asserts=false -Dtests.file.encoding=ISO-8859-1 causes the following errors/exceptions: &#13;
[junit4]    &gt; Throwable #1: org.junit.ComparisonFailure: expected:&lt;...9942E65A94EC1-002/te[mpDir-003/solrj_test_core_props_shard1_replica1]&gt; but was:&lt;...9942E65A94EC1-002/te[stPropertyParamsForCreate-001/instanceDir-fmchl]&gt;&#13;
   [junit4]    &gt; 	at __randomizedtesting.SeedInfo.seed([8219942E65A94EC1:3FF1A3612F62EFD]:0)&#13;
   [junit4]    &gt; 	at org.apache.solr.cloud.CollectionsAPIDistributedZkTest.checkInstanceDirs(CollectionsAPIDistributedZkTest.java:1154)&#13;
   [junit4]    &gt; 	at org.apache.solr.cloud.CollectionsAPIDistributedZkTest.testCollectionsAPI(CollectionsAPIDistributedZkTest.java:901)&#13;
   [junit4]    &gt; 	at org.apache.solr.cloud.CollectionsAPIDistributedZkTest.doTest(CollectionsAPIDistributedZkTest.java:205)&#13;
   [junit4]    &gt; 	at org.apache.solr.BaseDistributedSearchTestCase.testDistribSearch(BaseDistributedSearchTestCase.java:869)&#13;
   [junit4]    &gt; 	at java.lang.Thread.run(Thread.java:745)&#13;
 and running it without that seed (and may be with the seed too) often leads to : &#13;
oasu.SolrIndexWriter.rollback ERROR Exception rolling back IndexWriter org.apache.lucene.store.AlreadyClosedException: refusing to delete any files: this IndexWriter hit an unrecoverable exception</description></buginformation><fixedFiles><file>solr.core.src.test.org.apache.solr.cloud.CollectionsAPIDistributedZkTest.java</file><file>solr.core.src.test.org.apache.solr.cloud.CollectionsAPISolrJTests.java</file></fixedFiles></bug><bug fixdate="2015-03-02 06:41:36" id="6864" opendate="2014-12-17 11:52:50"><buginformation><summary>[SOLR-6864] Support registering searcher listeners in SolrCoreAware.inform(SolrCore) method - ASF JIRA</summary><description>I'm marking this Jira as Bug because we already have components that do this (SuggestComponent and SpellcheckComponent), however, listeners registered at this stage not always work. From https://issues.apache.org/jira/browse/SOLR-6845?focusedCommentId=14250350&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14250350 Trying to add some unit tests to this feature I found another issue. SuggestComponent and SpellcheckComponent rely on a firstSearcherListener to load (and in this case, also build) some structures. These firstSearcherListeners are registered on SolrCoreAware.inform(), however the first searcher listener task is only added to the queue of warming tasks if there is at least one listener registered at the time of the first searcher creation (before SolrCoreAware.inform() is ever called). See SolrCore.java &#13;
        if (currSearcher == null &amp;&amp; firstSearcherListeners.size() &gt; 0) {&#13;
          future = searcherExecutor.submit(new Callable() {&#13;
            @Override&#13;
            public Object call() throws Exception {&#13;
              try {&#13;
                for (SolrEventListener listener : firstSearcherListeners) {&#13;
                  listener.newSearcher(newSearcher, null);&#13;
                }&#13;
              } catch (Throwable e) {&#13;
                SolrException.log(log, null, e);&#13;
                if (e instanceof Error) {&#13;
                  throw (Error) e;&#13;
                }&#13;
              }&#13;
              return null;&#13;
            }&#13;
          });&#13;
        }&#13;
 I'll create a new Jira for this</description></buginformation><fixedFiles><file>a.solr.core.src.test.org.apache.solr.search.TestIndexSearcher.java</file><file>a.solr.core.src.java.org.apache.solr.core.SolrCore.java</file></fixedFiles></bug><bug fixdate="2015-02-26 05:33:21" id="6856" opendate="2014-12-17 12:40:04"><buginformation><summary>[SOLR-6856] regression in /update/extract ? ref guide examples of fmap &amp; xpath don't seem to be working - ASF JIRA</summary><description>I updated this page to know about hte new bin/solr and example/exampledocs structure/contents... https://cwiki.apache.org/confluence/display/solr/Uploading+Data+with+Solr+Cell+using+Apache+Tika however i noticed that several of the examples listed on that page didn't seem to work any more – notably... examples using "fmap" don't seem to create the fields they say they will examples using "xpath" don't seem to create any docs at all Specific examples i had problems with... curl "http://localhost:8983/solr/techproducts/update/extract?literal.id=doc2&amp;captureAttr=true&amp;defaultField=text&amp;fmap.div=foo_t&amp;capture=div&amp;commit=true" -F "sample=@example/exampledocs/sample.html"&#13;
curl "http://localhost:8983/solr/techproducts/update/extract?literal.id=doc3&amp;captureAttr=true&amp;defaultField=text&amp;capture=div&amp;fmap.div=foo_t&amp;boost.foo_t=3&amp;commit=true" -F "sample=@example/exampledocs/sample.html"&#13;
curl "http://localhost:8983/solr/techproducts/update/extract?literal.id=doc4&amp;captureAttr=true&amp;defaultField=text&amp;capture=div&amp;fmap.div=foo_t&amp;boost.foo_t=3&amp;literal.blah_s=Bah&amp;commit=true" -F "sample=@example/exampledocs/sample.html"&#13;
curl "http://localhost:8983/solr/techproducts/update/extract?literal.id=doc5&amp;captureAttr=true&amp;defaultField=text&amp;capture=div&amp;fmap.div=foo_t&amp;boost.foo_t=3&amp;literal.id=id&amp;xpath=/xhtml:html/xhtml:body/xhtml:div/descendant:node()&amp;commit=true" -F "sample=@example/exampledocs/sample.html"&#13;
 ...none of these example commands produced an error, but they also didn't seem to create the fields/docs they said they would (ie: no "foo_t" field was created)</description></buginformation><fixedFiles><file>solr.contrib.extraction.src.test.org.apache.solr.handler.extraction.ExtractingRequestHandlerTest.java</file><file>solr.contrib.extraction.src.java.org.apache.solr.handler.extraction.ExtractingDocumentLoader.java</file></fixedFiles></bug><bug fixdate="2015-01-28 01:08:45" id="6854" opendate="2014-12-16 07:25:10"><buginformation><summary>[SOLR-6854] Stale cached state in CloudSolrClient - ASF JIRA</summary><description>CloudSolrServer’s cached state is not being updated for a newly created collection if we started polling for the collection state too early and a "down" state is cached. Requests to the newly created collection continues to fail with "No live SolrServers available to handle this request" until the cache is invalidated by time. Logging on the client side reveals that while the state in ZkStateReader is updated to "active", the cached state in CloudSolrServer remains in "down". CloudSolrServer cached state: DocCollection(collection-1418250319268)={ "shards":{"shard1":{ "range":"80000000-7fffffff", "state":"active", "replicas":{"core_node1":{ "state":"down", "base_url":"http://localhost:8983/solr", "core":"collection-1418250319268_shard1_replica1", "node_name":"localhost:8983_solr"}}}}, "maxShardsPerNode":"1", "external":"true", "router": Unknown macro: { "name"} , "replicationFactor":"1”} ZkStateReader state: DocCollection(collection-1418250319268)={ "shards":{"shard1":{ "range":"80000000-7fffffff", "state":"active", "replicas":{"core_node1":{ "state":"active", "base_url":"http://localhost:8983/solr", "core":"collection-1418250319268_shard1_replica1", "node_name":"localhost:8983_solr", "leader":"true"}}}}, "maxShardsPerNode":"1", "router": Unknown macro: { "name"} , "external":"true", "replicationFactor":"1”}</description></buginformation><fixedFiles><file>solr.solrj.src.java.org.apache.solr.client.solrj.impl.CloudSolrClient.java</file></fixedFiles></bug></bugrepository>